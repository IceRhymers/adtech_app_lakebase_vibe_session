{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: databricks-sdk==0.61.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (0.61.0)\n",
      "Requirement already satisfied: pyarrow<20 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (19.0.1)\n",
      "Requirement already satisfied: databricks-agents==1.2.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: mlflow<=3.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (3.1.0)\n",
      "Requirement already satisfied: databricks-vectorsearch==0.57 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (0.57)\n",
      "Requirement already satisfied: langchain in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain_core in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (0.3.72)\n",
      "Requirement already satisfied: databricks-langchain in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (0.6.0)\n",
      "Requirement already satisfied: bs4 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (0.0.2)\n",
      "Requirement already satisfied: markdownify in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: dotenv in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (0.9.9)\n",
      "Requirement already satisfied: requests<3,>=2.28.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-sdk==0.61.0) (2.32.4)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-sdk==0.61.0) (2.40.3)\n",
      "Requirement already satisfied: databricks-connect in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-agents==1.2.0) (16.1.6)\n",
      "Requirement already satisfied: dataclasses-json in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-agents==1.2.0) (0.6.7)\n",
      "Requirement already satisfied: jinja2>=3.0.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-agents==1.2.0) (3.1.6)\n",
      "Requirement already satisfied: mlflow-skinny<4.0.0,>=3.1.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-agents==1.2.0) (3.1.0)\n",
      "Requirement already satisfied: tenacity>=8.5 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-agents==1.2.0) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.8.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-agents==1.2.0) (0.9.0)\n",
      "Requirement already satisfied: tqdm in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-agents==1.2.0) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=2.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-agents==1.2.0) (2.5.0)\n",
      "Requirement already satisfied: pydantic>=2 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-agents==1.2.0) (2.11.7)\n",
      "Requirement already satisfied: whenever==0.7.3 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-agents==1.2.0) (0.7.3)\n",
      "Requirement already satisfied: boto3>1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-agents==1.2.0) (1.40.0)\n",
      "Requirement already satisfied: botocore in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-agents==1.2.0) (1.40.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-vectorsearch==0.57) (5.29.5)\n",
      "Requirement already satisfied: deprecation>=2 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-vectorsearch==0.57) (2.1.0)\n",
      "Requirement already satisfied: Flask<4 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow<=3.1) (3.0.3)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow<=3.1) (1.13.1)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow<=3.1) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow<=3.1) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow<=3.1) (23.0.0)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow<=3.1) (3.10.5)\n",
      "Requirement already satisfied: numpy<3 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow<=3.1) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow<=3.1) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow<=3.1) (1.7.1)\n",
      "Requirement already satisfied: scipy<2 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow<=3.1) (1.16.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow<=3.1) (2.0.30)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle<4 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (3.1.1)\n",
      "Requirement already satisfied: fastapi<1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (0.115.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (3.1.45)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (1.36.0)\n",
      "Requirement already satisfied: packaging<26 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (24.2)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (6.0.2)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (4.14.1)\n",
      "Requirement already satisfied: uvicorn<1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (0.30.6)\n",
      "Requirement already satisfied: Mako in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow<=3.1) (1.3.10)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (0.38.6)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from Flask<4->mlflow<=3.1) (3.0.6)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from Flask<4->mlflow<=3.1) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from Flask<4->mlflow<=3.1) (1.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk==0.61.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk==0.61.0) (4.9.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from graphene<4->mlflow<=3.1) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from graphene<4->mlflow<=3.1) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from graphene<4->mlflow<=3.1) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (3.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from matplotlib<4->mlflow<=3.1) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from matplotlib<4->mlflow<=3.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from matplotlib<4->mlflow<=3.1) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from matplotlib<4->mlflow<=3.1) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from matplotlib<4->mlflow<=3.1) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from matplotlib<4->mlflow<=3.1) (3.2.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (0.57b0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from pandas<3->mlflow<=3.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from pandas<3->mlflow<=3.1) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from pydantic>=2->databricks-agents==1.2.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from pydantic>=2->databricks-agents==1.2.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from pydantic>=2->databricks-agents==1.2.0) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow<=3.1) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk==0.61.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk==0.61.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk==0.61.0) (2025.7.14)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk==0.61.0) (0.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from scikit-learn<2->mlflow<=3.1) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from scikit-learn<2->mlflow<=3.1) (3.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from starlette<0.39.0,>=0.37.2->fastapi<1->mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi<1->mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from uvicorn<1->mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (0.16.0)\n",
      "Requirement already satisfied: ipython<10,>=8 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-sdk[notebook]) (9.4.0)\n",
      "Requirement already satisfied: ipywidgets<9,>=8 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-sdk[notebook]) (8.1.7)\n",
      "Requirement already satisfied: decorator in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (5.14.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from ipywidgets<9,>=8->databricks-sdk[notebook]) (0.2.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from ipywidgets<9,>=8->databricks-sdk[notebook]) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from ipywidgets<9,>=8->databricks-sdk[notebook]) (3.0.15)\n",
      "Requirement already satisfied: wcwidth in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython<10,>=8->databricks-sdk[notebook]) (0.2.13)\n",
      "Requirement already satisfied: azure-storage-file-datalake>12 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow[databricks]) (12.21.0)\n",
      "Requirement already satisfied: google-cloud-storage>=1.30.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from mlflow[databricks]) (3.2.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from langchain) (0.4.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
      "Requirement already satisfied: databricks-ai-bridge>=0.6.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-langchain) (0.6.0)\n",
      "Requirement already satisfied: unitycatalog-langchain>=0.2.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (0.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.56.4 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-connect->databricks-agents==1.2.0) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status>=1.59.3 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-connect->databricks-agents==1.2.0) (1.71.2)\n",
      "Requirement already satisfied: grpcio>=1.59.3 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-connect->databricks-agents==1.2.0) (1.74.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-connect->databricks-agents==1.2.0) (0.10.9.7)\n",
      "Requirement already satisfied: setuptools>=68.0.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-connect->databricks-agents==1.2.0) (80.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from bs4) (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from beautifulsoup4->bs4) (2.7)\n",
      "Requirement already satisfied: python-dotenv in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from dotenv) (1.1.1)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow[databricks]) (1.35.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.26.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow[databricks]) (12.26.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow[databricks]) (0.7.2)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from azure-storage-blob>=12.26.0->azure-storage-file-datalake>12->mlflow[databricks]) (45.0.5)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from boto3>1->databricks-agents==1.2.0) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from boto3>1->databricks-agents==1.2.0) (0.13.1)\n",
      "Requirement already satisfied: cffi>=1.14 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.26.0->azure-storage-file-datalake>12->mlflow[databricks]) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from cffi>=1.14->cryptography>=2.1.4->azure-storage-blob>=12.26.0->azure-storage-file-datalake>12->mlflow[databricks]) (2.22)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-ai-bridge>=0.6.0->databricks-langchain) (0.9.0)\n",
      "Requirement already satisfied: openai in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-sdk[openai]>=0.58.0->databricks-agents==1.2.0) (1.98.0)\n",
      "Requirement already satisfied: langchain-openai in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-sdk[openai]>=0.58.0->databricks-agents==1.2.0) (0.3.28)\n",
      "Requirement already satisfied: httpx in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from databricks-sdk[openai]>=0.58.0->databricks-agents==1.2.0) (0.28.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.15.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]) (2.25.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]) (1.7.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage>=1.30.0->mlflow[databricks]) (1.26.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from jedi>=0.16->ipython<10,>=8->databricks-sdk[notebook]) (0.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from jinja2>=3.0.0->databricks-agents==1.2.0) (2.1.5)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from httpx->databricks-sdk[openai]>=0.58.0->databricks-agents==1.2.0) (1.0.9)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from pexpect>4.3->ipython<10,>=8->databricks-sdk[notebook]) (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from tiktoken>=0.8.0->databricks-agents==1.2.0) (2025.7.34)\n",
      "Requirement already satisfied: langchain-community>=0.2.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (0.3.27)\n",
      "Requirement already satisfied: unitycatalog-ai in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (0.3.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (3.12.15)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (0.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from dataclasses-json->databricks-agents==1.2.0) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from dataclasses-json->databricks-agents==1.2.0) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->databricks-agents==1.2.0) (1.1.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from openai->databricks-sdk[openai]>=0.58.0->databricks-agents==1.2.0) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from openai->databricks-sdk[openai]>=0.58.0->databricks-agents==1.2.0) (0.10.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from stack_data->ipython<10,>=8->databricks-sdk[notebook]) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from stack_data->ipython<10,>=8->databricks-sdk[notebook]) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from stack_data->ipython<10,>=8->databricks-sdk[notebook]) (0.2.3)\n",
      "Requirement already satisfied: nest-asyncio in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from unitycatalog-ai->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (1.6.0)\n",
      "Requirement already satisfied: unitycatalog-client in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from unitycatalog-ai->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (0.3.0)\n",
      "Requirement already satisfied: aiohttp-retry>=2.8.3 in /Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages (from unitycatalog-client->unitycatalog-ai->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (2.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install 'databricks-sdk==0.61.0' 'pyarrow<20' 'databricks-sdk[notebook]' 'databricks-agents==1.2.0' 'mlflow<=3.1' 'mlflow[databricks]' 'databricks-vectorsearch==0.57' 'langchain' 'langchain_core' 'databricks-langchain' 'bs4' 'markdownify' 'dotenv'\n",
    "import os\n",
    "if os.environ.get(\"DATABRICKS_RUNTIME_VERSION\"):\n",
    "    dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ffec623f99547ed8020afe27fd6497f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Label(value='vector_search_endpoint'), Text(value='one-env-shared-endpoint-7')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d6ac10dc1d4a2fb80f79b4c69b8560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Label(value='vector_search_index'), Text(value='tanner_wendland.default.chat_history_index')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b593dd70d014fd0b1c2c985d0114d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Label(value='llm_model_serving_endpoint_name'), Text(value='databricks-claude-3-7-sonnet')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5479dfe51da42d1b16e975518f88727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Label(value='target_catalog'), Text(value='tanner_wendland')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0ebb6183a246f8980d9eae29dee220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Label(value='target_schema'), Text(value='default')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.widgets.text(\"vector_search_endpoint\", \"one-env-shared-endpoint-7\")\n",
    "dbutils.widgets.text(\"vector_search_index\", \"tanner_wendland.default.chat_history_index\")\n",
    "dbutils.widgets.text(\"llm_model_serving_endpoint_name\", \"databricks-claude-3-7-sonnet\")\n",
    "dbutils.widgets.text(\"target_catalog\", \"tanner_wendland\")\n",
    "dbutils.widgets.text(\"target_schema\", \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search_endpoint = dbutils.widgets.get(\"vector_search_endpoint\")\n",
    "vector_search_index = dbutils.widgets.get(\"vector_search_index\")\n",
    "llm_model_serving_endpoint_name = dbutils.widgets.get(\"llm_model_serving_endpoint_name\")\n",
    "target_catalog = dbutils.widgets.get(\"target_catalog\")\n",
    "target_schema = dbutils.widgets.get(\"target_schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "import os\n",
    "\n",
    "vsc: VectorSearchClient = None\n",
    "if os.environ.get(\"DATABRICKS_RUNTIME_VERSION\"):\n",
    "    vsc = VectorSearchClient(disable_notice=True)\n",
    "else:\n",
    "    import dotenv\n",
    "    dotenv.load_dotenv('.env')\n",
    "    vsc = VectorSearchClient(disable_notice=True, workspace_url=os.environ.get(\"DATABRICKS_HOST\"), personal_access_token=os.environ.get(\"DATABRICKS_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a Personal Authentication Token (PAT). Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[\"Hello! I'm starting a new chat history!\", 0.004474774]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Tell me about the chat history\"\n",
    "\n",
    "results = vsc.get_index(vector_search_endpoint, vector_search_index).similarity_search(\n",
    "  query_text=question,\n",
    "  columns=[\"message_content\"],\n",
    "  num_results=1)\n",
    "docs = results.get('result', {}).get('data_array', [])\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chain Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_config = {\n",
    "    \"llm_model_serving_endpoint_name\": llm_model_serving_endpoint_name,\n",
    "    \"vector_search_endpoint_name\": vector_search_endpoint,  # the endoint we want to use for vector search\n",
    "    \"vector_search_index\": vector_search_index,\n",
    "    \"llm_prompt_template\": \"\"\"You are an assistant that answers questions. You have access to a vector search tool that searches previous conversations, but you should primarily use the immediate conversation context provided.\n",
    "\n",
    "Current conversation context: {context}\n",
    "\n",
    "Instructions:\n",
    "1. First, use the current conversation context above to answer questions\n",
    "2. Only use the vector search tool if the question explicitly refers to information from previous conversations that is NOT in the current context\n",
    "3. If the current conversation context contains sufficient information to answer the question, do NOT use the vector search tool\n",
    "4. The vector search tool should be used sparingly, only when the user is clearly asking about something from their chat history that isn't in the current conversation\"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Search Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_config = {\n",
    "    \"parameters\": {\n",
    "        \"k\": 3,\n",
    "        \"query_type\": \"hybrid\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "# combine dynamic and static filters for vector search\n",
    "def create_configurable_with_filters(input: Dict, retriever_config: Dict) -> Dict:\n",
    "   \"\"\"\n",
    "   create configurable object with filters.\n",
    "   Args:\n",
    "       input: The input data containing filters.\n",
    "   Returns:\n",
    "       A configurable object with filters added to the search_kwargs.\n",
    "   \"\"\"\n",
    "   if \"custom_inputs\" in input:\n",
    "       filters = input[\"custom_inputs\"][\"filters\"]\n",
    "   else:\n",
    "       filters = {}\n",
    "   print(filters)\n",
    "   configurable = {\n",
    "       \"configurable\": {\n",
    "           \"search_kwargs\": {\n",
    "               \"k\": retriever_config.get(\"parameters\")[\"k\"],\n",
    "               \"query_type\": retriever_config.get(\"parameters\").get(\"query_type\"),\n",
    "               \"filter\": filters\n",
    "           }\n",
    "       }\n",
    "   }\n",
    "   return configurable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Basic Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "Passage: Based on the chat history provided, the first message you sent was:\n",
      "\n",
      "\"I'm looking for a new laptop for work. I need something with good performance for running multiple applications simultaneously, a decent battery life, and preferably under $1500. Any recommendations?\"\n",
      "\n",
      "This was your initial query that started our conversation about laptop recommendations.\n",
      "Passage: Hello! I'm starting a new chat history!\n",
      "Passage: From the messages you've given what was the first message I sent?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks_langchain import DatabricksVectorSearch\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables.utils import ConfigurableField\n",
    "\n",
    "## Load the chain's configuration\n",
    "model_config = mlflow.models.ModelConfig(development_config=chain_config)\n",
    "\n",
    "## Turn the Vector Search index into a LangChain retriever\n",
    "vector_search_as_retriever = DatabricksVectorSearch(\n",
    "    endpoint=model_config.get(\"vector_search_endpoint_name\"),\n",
    "    index_name=model_config.get(\"vector_search_index\"),\n",
    "    columns=[\"id\", \"message_content\", \"user_name\"],\n",
    ").as_retriever(search_kwargs=retriever_config.get(\"parameters\"))\n",
    "\n",
    "configurable_vs_retriever = vector_search_as_retriever.configurable_fields(\n",
    "   search_kwargs=ConfigurableField(\n",
    "       id=\"search_kwargs\",\n",
    "       name=\"Search Kwargs\",\n",
    "       description=\"The search kwargs to use\",\n",
    "   )\n",
    ")\n",
    "\n",
    "\n",
    "# Method to format the docs returned by the retriever into the prompt (keep only the text from chunks)\n",
    "def format_context(docs):\n",
    "    chunk_contents = [f\"Passage: {d.page_content}\\n\" for d in docs]\n",
    "    return \"\".join(chunk_contents)\n",
    "\n",
    "#Let's try our retriever chain:\n",
    "relevant_docs = (configurable_vs_retriever | RunnableLambda(format_context)| StrOutputParser()).invoke('What was my chat history idea?')\n",
    "\n",
    "print(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from databricks_langchain.chat_models import ChatDatabricks\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from operator import itemgetter\n",
    "\n",
    "def vector_search_with_filters(query: str, input_data: dict = None) -> str:\n",
    "    \"\"\"\n",
    "    Search the vector database for relevant documents.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query string\n",
    "        input_data: Optional input data containing filters\n",
    "    \n",
    "    Returns:\n",
    "        Formatted context from retrieved documents\n",
    "    \"\"\"\n",
    "    if input_data is None:\n",
    "        input_data = {}\n",
    "    \n",
    "    # Apply filters securely\n",
    "    config = create_configurable_with_filters(input_data, retriever_config)\n",
    "    \n",
    "    # Retrieve documents\n",
    "    docs = configurable_vs_retriever.invoke(query, config=config)\n",
    "    \n",
    "    # Format and return context\n",
    "    return format_context(docs)\n",
    "\n",
    "vector_search_tool = Tool(\n",
    "    name=\"search_chat_history\",\n",
    "    description=\"Retreive chat history from this vector search index for the current user, use this tool to answer questions that may refer to previous conversations but only if we can't answer the question with the immediate conversation context provided.\",\n",
    "    func=lambda query: vector_search_with_filters(query, {}),  # Default case without filters\n",
    ")\n",
    "\n",
    "# Updated prompt template for tool-calling agent\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", model_config.get('llm_prompt_template')),\n",
    "    (\"user\", \"{question}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "# Our foundation model answering the final prompt\n",
    "model = ChatDatabricks(\n",
    "    endpoint=model_config.get(\"llm_model_serving_endpoint_name\"),\n",
    "    extra_params={\"temperature\": 0.01, \"max_tokens\": 500}\n",
    ")\n",
    "\n",
    "agent = create_tool_calling_agent(model, [vector_search_tool], prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=[vector_search_tool], verbose=True)\n",
    "\n",
    "def extract_user_query_string(chat_messages_array):\n",
    "    return chat_messages_array[-1][\"content\"]\n",
    "\n",
    "def extract_context_string(chat_messages_array):\n",
    "    return '\\n'.join([f\"Role: {message['role']} - Content: {message['content']}\" for message in chat_messages_array[:-1]])\n",
    "\n",
    "###########\n",
    "# RAG Chain with Tool\n",
    "############\n",
    "def rag_chain_with_tool(input_data: dict) -> str:\n",
    "    \"\"\"\n",
    "    RAG chain that uses vector search as a tool with proper filtering.\n",
    "    \n",
    "    Args:\n",
    "        input_data: Input containing messages and optional custom_inputs with filters\n",
    "    \n",
    "    Returns:\n",
    "        Generated response\n",
    "    \"\"\"\n",
    "    # Extract user query\n",
    "    user_query = extract_user_query_string(input_data[\"messages\"])\n",
    "    \n",
    "    # Create a modified vector search tool that includes the filters from input_data\n",
    "    def filtered_vector_search(query: str) -> str:\n",
    "        return vector_search_with_filters(query, input_data)\n",
    "    \n",
    "    # Update the tool with the filtered version\n",
    "    filtered_tool = Tool(\n",
    "        name=\"search_chat_history\",\n",
    "        description=\"Retreive chat history from this vector search index for the current user, use this tool to answer questions that may refer to previous conversations\",\n",
    "        func=filtered_vector_search,\n",
    "    )\n",
    "    \n",
    "    # Create new agent executor with the filtered tool\n",
    "    filtered_agent = create_tool_calling_agent(model, [filtered_tool], prompt)\n",
    "    filtered_agent_executor = AgentExecutor(agent=filtered_agent, tools=[filtered_tool], verbose=True)\n",
    "\n",
    "    context = extract_context_string(input_data[\"messages\"])\n",
    "    print(context)\n",
    "    # Execute the agent\n",
    "    result = filtered_agent_executor.invoke({\"question\": user_query, \"context\": context})\n",
    "    return result[\"output\"]\n",
    "\n",
    "# Create a runnable version of the chain\n",
    "chain = RunnableLambda(rag_chain_with_tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search WITHOUT Chat Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_chat_history` with `idea`\n",
      "responded: I'll need to search your chat history to find information about your idea. Let me do that for you.\n",
      "\n",
      "\u001b[0m{}\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "\u001b[36;1m\u001b[1;3mPassage: test\n",
      "Passage: I don't see any previous conversations where you've mentioned your favorite fruit. Could you please let me know what fruit you like? Once you share that information, I'll remember it for future conversations.\n",
      "Passage: test 12\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mI don't see any specific chat history about an idea you've shared previously. The search results don't show any detailed information about an idea you might have mentioned. \n",
      "\n",
      "If you're referring to a specific idea you shared in a previous conversation, could you provide a bit more context or details about what idea you're referring to? This would help me locate the relevant information in your chat history.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I don't see any specific chat history about an idea you've shared previously. The search results don't show any detailed information about an idea you might have mentioned. \n",
      "\n",
      "If you're referring to a specific idea you shared in a previous conversation, could you provide a bit more context or details about what idea you're referring to? This would help me locate the relevant information in your chat history.\n"
     ]
    }
   ],
   "source": [
    "input_example_no_filter = {\"messages\": [ {\"role\": \"user\", \"content\": \"What was my chat history idea?\"}]}\n",
    "answer_no_filter = chain.invoke(input_example_no_filter)\n",
    "print(answer_no_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search WITH filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_chat_history` with `chat history idea`\n",
      "responded: I'll help you find information about your chat history idea. Let me search your previous conversations to locate this information.\n",
      "\n",
      "\u001b[0m{'user_name': 'tanner.wendland@databricks.com'}\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "\u001b[36;1m\u001b[1;3mPassage: Hello! I'm starting a new chat history!\n",
      "Passage: Based on the chat history provided, the first message you sent was:\n",
      "\n",
      "\"I'm looking for a new laptop for work. I need something with good performance for running multiple applications simultaneously, a decent battery life, and preferably under $1500. Any recommendations?\"\n",
      "\n",
      "This was your initial query that started our conversation about laptop recommendations.\n",
      "Passage: test chat 2\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mBased on searching your chat history, I don't see a specific \"chat history idea\" that you previously mentioned. I can see that you started some conversations, including one where you were looking for laptop recommendations under $1500, and there appear to be some test chats.\n",
      "\n",
      "Could you provide more details about the specific idea you're referring to? Perhaps you could share when you might have discussed this idea or give me more context so I can help you locate the right information.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on searching your chat history, I don't see a specific \"chat history idea\" that you previously mentioned. I can see that you started some conversations, including one where you were looking for laptop recommendations under $1500, and there appear to be some test chats.\n",
      "\n",
      "Could you provide more details about the specific idea you're referring to? Perhaps you could share when you might have discussed this idea or give me more context so I can help you locate the right information.\n"
     ]
    }
   ],
   "source": [
    "input_example = {\"messages\": [ {\"role\": \"user\", \"content\": \"What was my chat history idea?\"}], \"custom_inputs\": {\"filters\": {\"user_name\": \"tanner.wendland@databricks.com\"}}}\n",
    "answer = chain.invoke(input_example)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: user - Content: What's the capital of Alaska?\n",
      "Role: assistant - Content: Juneau\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_chat_history` with `Alaska capital Juneau Anchorage distance`\n",
      "responded: I'll need to find information about the distance between Anchorage and Juneau (the capital of Alaska that we discussed earlier).\n",
      "\n",
      "\u001b[0m{'user_name': 'fake.user@databricks.com'}\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "\u001b[36;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mBased on our previous conversation, you asked about the capital of Alaska, which is Juneau. Now you're asking about the distance from Anchorage to Juneau.\n",
      "\n",
      "Juneau and Anchorage are approximately 571 miles (919 kilometers) apart as the crow flies. However, it's important to note that there is no direct road connection between these two major Alaskan cities. Juneau is actually inaccessible by road - you can only reach it by air or sea. This is quite unusual for a state capital in the United States.\n",
      "\n",
      "If you were to travel between these cities, you would typically need to fly, which takes about 1.5 hours, or take the Alaska Marine Highway System (ferry), which is a much longer journey.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on our previous conversation, you asked about the capital of Alaska, which is Juneau. Now you're asking about the distance from Anchorage to Juneau.\n",
      "\n",
      "Juneau and Anchorage are approximately 571 miles (919 kilometers) apart as the crow flies. However, it's important to note that there is no direct road connection between these two major Alaskan cities. Juneau is actually inaccessible by road - you can only reach it by air or sea. This is quite unusual for a state capital in the United States.\n",
      "\n",
      "If you were to travel between these cities, you would typically need to fly, which takes about 1.5 hours, or take the Alaska Marine Highway System (ferry), which is a much longer journey.\n"
     ]
    }
   ],
   "source": [
    "input_example = {\"messages\": [ {\"role\": \"user\", \"content\": \"What's the capital of Alaska?\"}, {\"role\": \"assistant\", \"content\": \"Juneau\"}, {\"role\": \"user\", \"content\": \"How far is it from Anchorage?\"}], \"custom_inputs\": {\"filters\": {\"user_name\": \"fake.user@databricks.com\"}}}\n",
    "answer = chain.invoke(input_example)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_chat_history` with `Databricks Genie`\n",
      "responded: I'll help you find information about Databricks Genie. Let me search for any previous conversations about this topic first.\n",
      "\n",
      "\u001b[0m{'user_name': 'tanner.wendland@databricks.com'}\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "\u001b[36;1m\u001b[1;3mPassage: Tell me about the product Genie from Databricks?\n",
      "Passage: I don't see any specific information about Databricks Genie in our previous conversations. Let me provide you with information about this product:\n",
      "\n",
      "# Databricks Genie\n",
      "\n",
      "Databricks Genie is an AI-powered data assistant that helps data teams work more efficiently with their data. Here are the key features and aspects of Databricks Genie:\n",
      "\n",
      "## Key Features:\n",
      "1. **Natural Language Interface**: Allows users to interact with data using conversational language rather than complex SQL or code.\n",
      "\n",
      "2. **Data Exploration**: Helps users explore and understand their data through natural language queries.\n",
      "\n",
      "3. **Code Generation**: Automatically generates SQL, Python, or other code based on natural language requests.\n",
      "\n",
      "4. **Data Visualization**: Creates visualizations and charts based on verbal or written requests.\n",
      "\n",
      "5. **Integration with Databricks Workspace**: Seamlessly works within the Databricks ecosystem, including Databricks SQL, notebooks, and other Databricks tools.\n",
      "\n",
      "## Benefits:\n",
      "- **Increased Productivity**: Reduces time spent writing complex queries or code.\n",
      "- **Democratized Data Access**: Makes data analysis accessible to team members with varying technical expertise.\n",
      "- **Accelerated Insights**: Helps teams discover patterns and insights in their data more quickly.\n",
      "- **Simplified Workflows**: Streamlines common data tasks through natural language commands.\n",
      "\n",
      "Genie is part of Databricks' broader AI-powered offerings that aim to make data analytics and machine learning more accessible and efficient for organizations of all sizes.\n",
      "\n",
      "Would you like to know more specific details about Databricks Genie, such as its implementation, pricing, or how it compares to other similar tools?\n",
      "Passage: Error calling model serving endpoint: Invalid input. Failed to parse input data. This model contains a tensor-based model signature with input names, which suggests a dictionary / a list of dictionaries input mapping input name to tensor or a pure list, but an input of `{\"messages\": [{\"role\": \"user\", \"content\": \"Hello! I'm starting a new chat history!\"}, {\"role\": \"assistant\", \"content\": \"Error calling model serving endpoint: Failed to enforce schema of data '{'messages': [{'content': \\\"Hello! I'm starting a new chat history!\\\", 'role': 'user'}]}' with schema '['messages': Array({content: string (required), role: string (required)}) (required), 'custom_inputs': {filters: {user_name: string (required)} (required)} (required)]'. Error: Model is missing inputs ['custom_inputs'].\"}, {\"role\": \"user\", \"content\": \"Are we working now?\"}, {\"role\": \"assistant\", \"content\": \"Error calling model serving endpoint: Failed to enforce schema of data '         0\\n0  columns\\n1    index\\n2     data' with schema '['messages': Array({content: string (required), role: string (required)}) (required), 'custom_inputs': {filters: {user_name: string (required)} (required)} (required)]'. Error: Model is missing inputs ['messages', 'custom_inputs']. Note that there were extra inputs: [0]\"}, {\"role\": \"user\", \"content\": \"Okay NOW are we working?\"}, {\"role\": \"assistant\", \"content\": \"Error calling model serving endpoint: the JSON object must be str, bytes or bytearray, not dict\"}, {\"role\": \"user\", \"content\": \"Are we working now?\"}, {\"role\": \"assistant\", \"content\": \"Error calling model serving endpoint: Failed to enforce schema of data '                                                   0\\n0  {\\\"messages\\\": [{\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Hel...' with schema '['messages': Array({content: string (required), role: string (required)}) (required), 'custom_inputs': {filters: {user_name: string (required)} (required)} (required)]'. Error: Model is missing inputs ['messages', 'custom_inputs']. Note that there were extra inputs: [0]\"}, {\"role\": \"user\", \"content\": \"Show me you're working now!\"}, {\"role\": \"assistant\", \"content\": \"Error calling model serving endpoint: Failed to enforce schema of data '      0\\n0     {\\n1     \\\"\\n2     c\\n3     o\\n4     l\\n...  ..\\n1892  }\\n1893  }\\n1894  ]\\n1895  ]\\n1896  }\\n\\n[1897 rows x 1 columns]' with schema '['messages': Array({content: string (required), role: string (required)}) (required), 'custom_inputs': {filters: {user_name: string (required)} (required)} (required)]'. Error: Model is missing inputs ['messages', 'custom_inputs']. Note that there were extra inputs: [0]\"}, {\"role\": \"user\", \"content\": \"test 12\"}, {\"role\": \"assistant\", \"content\": \"Error calling model serving endpoint: Failed to enforce schema of data '      0\\n0     {\\n1     \\\"\\n2     c\\n3     o\\n4     l\\n...  ..\\n2453  }\\n2454  }\\n2455  ]\\n2456  ]\\n2457  }\\n\\n[2458 rows x 1 columns]' with schema '['messages': Array({content: string (required), role: string (required)}) (required), 'custom_inputs': {filters: {user_name: string (required)} (required)} (required)]'. Error: Model is missing inputs ['messages', 'custom_inputs']. Note that there were extra inputs: [0]\"}, {\"role\": \"user\", \"content\": \"test message again\"}, {\"role\": \"assistant\", \"content\": \"Error calling model serving endpoint: list index out of range\"}, {\"role\": \"user\", \"content\": \"last test message for today\"}, {\"role\": \"assistant\", \"content\": \"Error calling model serving endpoint: list index out of range\"}, {\"role\": \"user\", \"content\": \"last message\"}, {\"role\": \"assistant\", \"content\": \"Error calling model serving endpoint: list index out of range\"}, {\"role\": \"user\", \"content\": \"mgt time\"}, {\"role\": \"assistant\", \"content\": \"Error calling model serving endpoint: Failed to enforce schema of data '               0\\n0       messages\\n1  custom_inputs' with schema '['messages': Array({content: string (required), role: string (required)}) (required), 'custom_inputs': {filters: {user_name: string (required)} (required)} (required)]'. Error: Model is missing inputs ['messages', 'custom_inputs']. Note that there were extra inputs: [0]\"}, {\"role\": \"user\", \"content\": \"Are we working now?\"}, {\"role\": \"assistant\", \"content\": \"Error calling model serving endpoint: Failed to enforce schema of data '      0\\n0     {\\n1     \\\"\\n2     m\\n3     e\\n4     s\\n...  ..\\n3988  m\\n3989  \\\"\\n3990  }\\n3991  }\\n3992  }\\n\\n[3993 rows x 1 columns]' with schema '['messages': Array({content: string (required), role: string (required)}) (required), 'custom_inputs': {filters: {user_name: string (required)} (required)} (required)]'. Error: Model is missing inputs ['messages', 'custom_inputs']. Note that there were extra inputs: [0]\"}, {\"role\": \"user\", \"content\": \"test chat 2\"}, {\"role\": \"assistant\", \"content\": \"Error calling model serving endpoint: Failed to enforce schema of data '      0\\n0     {\\n1     \\\"\\n2     m\\n3     e\\n4     s\\n...  ..\\n4562  m\\n4563  \\\"\\n4564  }\\n4565  }\\n4566  }\\n\\n[4567 rows x 1 columns]' with schema '['messages': Array({content: string (required), role: string (required)}) (required), 'custom_inputs': {filters: {user_name: string (required)} (required)} (required)]'. Error: Model is missing inputs ['messages', 'custom_inputs']. Note that there were extra inputs: [0]\"}, {\"role\": \"user\", \"content\": \"test\"}, {\"role\": \"assistant\", \"content\": \"Error calling model serving endpoint: Failed to enforce schema of data '      0\\n0     {\\n1     \\\"\\n2     m\\n3     e\\n4     s\\n...  ..\\n5129  m\\n5130  \\\"\\n5131  }\\n5132  }\\n5133  }\\n\\n[5134 rows x 1 columns]' with schema '['messages': Array({content: string (required), role: string (required)}) (required), 'custom_inputs': {filters: {user_name: string (required)} (required)} (required)]'. Error: Model is missing inputs ['messages', 'custom_inputs']. Note that there were extra inputs: [0]\"}, {\"role\": \"user\", \"content\": \"another test\"}, {\"role\": \"assistant\", \"content\": \"Error calling model serving endpoint: Failed to enforce schema of data '{'input': '{\\\"messages\\\": [{\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Hello! I\\\\'m starting a new chat history!\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Error calling model serving endpoint: Failed to enforce schema of data \\\\'{\\\\'messages\\\\': [{\\\\'content\\\\': \\\\\\\\\\\"Hello! I\\\\'m starting a new chat history!\\\\\\\\\\\", \\\\'role\\\\': \\\\'user\\\\'}]}\\\\' with schema \\\\'[\\\\'messages\\\\': Array({content: string (required), role: string (required)}) (required), \\\\'custom_inputs\\\\': {filters: {user_name: string (required)} (required)} (required)]\\\\'. Error: Model is missing inputs [\\\\'custom_inputs\\\\'].\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Are we working now?\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Error calling model serving endpoint: Failed to enforce schema of data \\\\'         0\\\\\\\\n0  columns\\\\\\\\n1    index\\\\\\\\n2     data\\\\' with schema \\\\'[\\\\'messages\\\\': Array({content: string (required), role: string (required)}) (required), \\\\'custom_inputs\\\\': {filters: {user_name: string (required)} (required)} (required)]\\\\'. Error: Model is missing inputs [\\\\'messages\\\\', \\\\'custom_inputs\\\\']. Note that there were extra inputs: [0]\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Okay NOW are we working?\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Error calling model serving endpoint: the JSON object must be str, bytes or bytearray, not dict\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Are we working now?\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Error calling model serving endpoint: Failed to enforce schema of data \\\\'                                                   0\\\\\\\\n0  {\\\\\\\\\\\"messages\\\\\\\\\\\": [{\\\\\\\\\\\"role\\\\\\\\\\\": \\\\\\\\\\\"user\\\\\\\\\\\", \\\\\\\\\\\"content\\\\\\\\\\\": \\\\\\\\\\\"Hel...\\\\' with schema \\\\'[\\\\'messages\\\\': Array({content: string (required), role: string (required)}) (required), \\\\'custom_inputs\\\\': {filters: {user_name: string (required)} (required)} (required)]\\\\'. Error: Model is missing inputs [\\\\'messages\\\\', \\\\'custom_inputs\\\\']. Note that there were extra inputs: [0]\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Show me you\\\\'re working now!\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Error calling model serving endpoint: Failed to enforce schema of data \\\\'      0\\\\\\\\n0     {\\\\\\\\n1     \\\\\\\\\\\"\\\\\\\\n2     c\\\\\\\\n3     o\\\\\\\\n4     l\\\\\\\\n...  ..\\\\\\\\n1892  }\\\\\\\\n1893  }\\\\\\\\n1894  ]\\\\\\\\n1895  ]\\\\\\\\n1896  }\\\\\\\\n\\\\\\\\n[1897 rows x 1 columns]\\\\' with schema \\\\'[\\\\'messages\\\\': Array({content: string (required), role: string (required)}) (required), \\\\'custom_inputs\\\\': {filters: {user_name: string (required)} (required)} (required)]\\\\'. Error: Model is missing inputs [\\\\'messages\\\\', \\\\'custom_inputs\\\\']. Note that there were extra inputs: [0]\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"test 12\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Error calling model serving endpoint: Failed to enforce schema of data \\\\'      0\\\\\\\\n0     {\\\\\\\\n1     \\\\\\\\\\\"\\\\\\\\n2     c\\\\\\\\n3     o\\\\\\\\n4     l\\\\\\\\n...  ..\\\\\\\\n2453  }\\\\\\\\n2454  }\\\\\\\\n2455  ]\\\\\\\\n2456  ]\\\\\\\\n2457  }\\\\\\\\n\\\\\\\\n[2458 rows x 1 columns]\\\\' with schema \\\\'[\\\\'messages\\\\': Array({content: string (required), role: string (required)}) (required), \\\\'custom_inputs\\\\': {filters: {user_name: string (required)} (required)} (required)]\\\\'. Error: Model is missing inputs [\\\\'messages\\\\', \\\\'custom_inputs\\\\']. Note that there were extra inputs: [0]\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"test message again\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Error calling model serving endpoint: list index out of range\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"last test message for today\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Error calling model serving endpoint: list index out of range\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"last message\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Error calling model serving endpoint: list index out of range\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"mgt time\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Error calling model serving endpoint: Failed to enforce schema of data \\\\'               0\\\\\\\\n0       messages\\\\\\\\n1  custom_inputs\\\\' with schema \\\\'[\\\\'messages\\\\': Array({content: string (required), role: string (required)}) (required), \\\\'custom_inputs\\\\': {filters: {user_name: string (required)} (required)} (required)]\\\\'. Error: Model is missing inputs [\\\\'messages\\\\', \\\\'custom_inputs\\\\']. Note that there were extra inputs: [0]\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Are we working now?\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Error calling model serving endpoint: Failed to enforce schema of data \\\\'      0\\\\\\\\n0     {\\\\\\\\n1     \\\\\\\\\\\"\\\\\\\\n2     m\\\\\\\\n3     e\\\\\\\\n4     s\\\\\\\\n...  ..\\\\\\\\n3988  m\\\\\\\\n3989  \\\\\\\\\\\"\\\\\\\\n3990  }\\\\\\\\n3991  }\\\\\\\\n3992  }\\\\\\\\n\\\\\\\\n[3993 rows x 1 columns]\\\\' with schema \\\\'[\\\\'messages\\\\': Array({content: string (required), role: string (required)}) (required), \\\\'custom_inputs\\\\': {filters: {user_name: string (required)} (required)} (required)]\\\\'. Error: Model is missing inputs [\\\\'messages\\\\', \\\\'custom_inputs\\\\']. Note that there were extra inputs: [0]\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"test chat 2\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Error calling model serving endpoint: Failed to enforce schema of data \\\\'      0\\\\\\\\n0     {\\\\\\\\n1     \\\\\\\\\\\"\\\\\\\\n2     m\\\\\\\\n3     e\\\\\\\\n4     s\\\\\\\\n...  ..\\\\\\\\n4562  m\\\\\\\\n4563  \\\\\\\\\\\"\\\\\\\\n4564  }\\\\\\\\n4565  }\\\\\\\\n4566  }\\\\\\\\n\\\\\\\\n[4567 rows x 1 columns]\\\\' with schema \\\\'[\\\\'messages\\\\': Array({content: string (required), role: string (required)}) (required), \\\\'custom_inputs\\\\': {filters: {user_name: string (required)} (required)} (required)]\\\\'. Error: Model is missing inputs [\\\\'messages\\\\', \\\\'custom_inputs\\\\']. Note that there were extra inputs: [0]\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"test\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Error calling model serving endpoint: Failed to enforce schema of data \\\\'      0\\\\\\\\n0     {\\\\\\\\n1     \\\\\\\\\\\"\\\\\\\\n2     m\\\\\\\\n3     e\\\\\\\\n4     s\\\\\\\\n...  ..\\\\\\\\n5129  m\\\\\\\\n5130  \\\\\\\\\\\"\\\\\\\\n5131  }\\\\\\\\n5132  }\\\\\\\\n5133  }\\\\\\\\n\\\\\\\\n[5134 rows x 1 columns]\\\\' with schema \\\\'[\\\\'messages\\\\': Array({content: string (required), role: string (required)}) (required), \\\\'custom_inputs\\\\': {filters: {user_name: string (required)} (required)} (required)]\\\\'. Error: Model is missing inputs [\\\\'messages\\\\', \\\\'custom_inputs\\\\']. Note that there were extra inputs: [0]\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"another test\\\"}], \\\"custom_inputs\\\": {\\\"filters\\\": {\\\"user_name\\\": \\\"tanner.wendland@databricks.com\\\"}}}'}' with schema '['messages': Array({content: string (required), role: string (required)}) (required), 'custom_inputs': {filters: {user_name: string (required)} (required)} (required)]'. Error: Model is missing inputs ['messages', 'custom_inputs']. Note that there were extra inputs: ['input']\"}, {\"role\": \"user\", \"content\": \"test 3\"}], \"custom_inputs\": {\"filters\": {\"user_name\": \"tanner.wendland@databricks.com\"}}}` was found.\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m# Databricks Genie\n",
      "\n",
      "Databricks Genie is an AI-powered data assistant designed to help data teams work more efficiently with their data. Here are the key features and capabilities of this product:\n",
      "\n",
      "## Key Features:\n",
      "\n",
      "1. **Natural Language Interface**: Allows users to interact with data using conversational language rather than complex SQL or code.\n",
      "\n",
      "2. **Data Exploration**: Helps users explore and understand their data through natural language queries.\n",
      "\n",
      "3. **Code Generation**: Automatically generates SQL, Python, or other code based on natural language requests.\n",
      "\n",
      "4. **Data Visualization**: Creates visualizations and charts based on verbal or written requests.\n",
      "\n",
      "5. **Integration with Databricks Workspace**: Seamlessly works within the Databricks ecosystem, including Databricks SQL, notebooks, and other Databricks tools.\n",
      "\n",
      "## Benefits:\n",
      "\n",
      "- **Increased Productivity**: Reduces time spent writing complex queries or code.\n",
      "- **Democratized Data Access**: Makes data analysis accessible to team members with varying technical expertise.\n",
      "- **Accelerated Insights**: Helps teams discover patterns and insights in their data more quickly.\n",
      "- **Simplified Workflows**: Streamlines common data tasks through natural language commands.\n",
      "\n",
      "Genie is part of Databricks' broader AI-powered offerings that aim to make data analytics and machine learning more accessible and efficient for organizations of all sizes.\n",
      "\n",
      "Would you like to know more specific details about Databricks Genie, such as its implementation, pricing, or how it compares to other similar tools?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "# Databricks Genie\n",
      "\n",
      "Databricks Genie is an AI-powered data assistant designed to help data teams work more efficiently with their data. Here are the key features and capabilities of this product:\n",
      "\n",
      "## Key Features:\n",
      "\n",
      "1. **Natural Language Interface**: Allows users to interact with data using conversational language rather than complex SQL or code.\n",
      "\n",
      "2. **Data Exploration**: Helps users explore and understand their data through natural language queries.\n",
      "\n",
      "3. **Code Generation**: Automatically generates SQL, Python, or other code based on natural language requests.\n",
      "\n",
      "4. **Data Visualization**: Creates visualizations and charts based on verbal or written requests.\n",
      "\n",
      "5. **Integration with Databricks Workspace**: Seamlessly works within the Databricks ecosystem, including Databricks SQL, notebooks, and other Databricks tools.\n",
      "\n",
      "## Benefits:\n",
      "\n",
      "- **Increased Productivity**: Reduces time spent writing complex queries or code.\n",
      "- **Democratized Data Access**: Makes data analysis accessible to team members with varying technical expertise.\n",
      "- **Accelerated Insights**: Helps teams discover patterns and insights in their data more quickly.\n",
      "- **Simplified Workflows**: Streamlines common data tasks through natural language commands.\n",
      "\n",
      "Genie is part of Databricks' broader AI-powered offerings that aim to make data analytics and machine learning more accessible and efficient for organizations of all sizes.\n",
      "\n",
      "Would you like to know more specific details about Databricks Genie, such as its implementation, pricing, or how it compares to other similar tools?\n"
     ]
    }
   ],
   "source": [
    "input_example = {\"messages\": [ {\"role\": \"user\", \"content\": \"What's the capital of France?\"}], \"custom_inputs\": {\"filters\": {\"user_name\": \"tanner.wendland@databricks.com\"}}}\n",
    "answer = chain.invoke(input_example)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAIN.PY\n",
    "\n",
    "This file is here to avoid serialziation issues with using a notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"ts\": \"2025-08-01 12:41:37,710\", \"level\": \"ERROR\", \"logger\": \"pyspark.sql.connect.client.logging\", \"msg\": \"GRPC Error received\", \"context\": {}, \"exception\": {\"class\": \"_InactiveRpcError\", \"msg\": \"<_InactiveRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.FAILED_PRECONDITION\\n\\tdetails = \\\"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=3c9af5a3-cdb1-4623-873f-7eeddad92a21, reason=INACTIVITY_TIMEOUT]. (requestId=8039babd-55cc-4fef-9b09-7be0080a1137)\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {grpc_status:9, grpc_message:\\\"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=3c9af5a3-cdb1-4623-873f-7eeddad92a21, reason=INACTIVITY_TIMEOUT]. (requestId=8039babd-55cc-4fef-9b09-7be0080a1137)\\\"}\\\"\\n>\", \"stacktrace\": [\"Traceback (most recent call last):\", \"  File \\\"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py\\\", line 2042, in config\", \"    resp = self._stub.Config(req, metadata=self.metadata())\", \"           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\", \"  File \\\"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_interceptor.py\\\", line 277, in __call__\", \"    response, ignored_call = self._with_call(\", \"                             ^^^^^^^^^^^^^^^^\", \"  File \\\"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_interceptor.py\\\", line 332, in _with_call\", \"    return call.result(), call\", \"           ^^^^^^^^^^^^^\", \"  File \\\"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_channel.py\\\", line 440, in result\", \"    raise self\", \"  File \\\"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_interceptor.py\\\", line 315, in continuation\", \"    response, call = self._thunk(new_method).with_call(\", \"                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\", \"  File \\\"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_channel.py\\\", line 1192, in with_call\", \"    return _end_unary_response_blocking(state, call, True, None)\", \"           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\", \"  File \\\"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_channel.py\\\", line 1006, in _end_unary_response_blocking\", \"    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\", \"    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\", \"grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\", \"\\tstatus = StatusCode.FAILED_PRECONDITION\", \"\\tdetails = \\\"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=3c9af5a3-cdb1-4623-873f-7eeddad92a21, reason=INACTIVITY_TIMEOUT]. (requestId=8039babd-55cc-4fef-9b09-7be0080a1137)\\\"\", \"\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {grpc_status:9, grpc_message:\\\"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=3c9af5a3-cdb1-4623-873f-7eeddad92a21, reason=INACTIVITY_TIMEOUT]. (requestId=8039babd-55cc-4fef-9b09-7be0080a1137)\\\"}\\\"\", \">\"]}}\n",
      "{\"ts\": \"2025-08-01 12:41:37,710\", \"level\": \"ERROR\", \"logger\": \"pyspark.sql.connect.client.logging\", \"msg\": \"GRPC Error received\", \"context\": {}, \"exception\": {\"class\": \"_InactiveRpcError\", \"msg\": \"<_InactiveRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.FAILED_PRECONDITION\\n\\tdetails = \\\"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=3c9af5a3-cdb1-4623-873f-7eeddad92a21, reason=INACTIVITY_TIMEOUT]. (requestId=8039babd-55cc-4fef-9b09-7be0080a1137)\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {grpc_status:9, grpc_message:\\\"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=3c9af5a3-cdb1-4623-873f-7eeddad92a21, reason=INACTIVITY_TIMEOUT]. (requestId=8039babd-55cc-4fef-9b09-7be0080a1137)\\\"}\\\"\\n>\", \"stacktrace\": [\"Traceback (most recent call last):\", \"  File \\\"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py\\\", line 2042, in config\", \"    resp = self._stub.Config(req, metadata=self.metadata())\", \"           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\", \"  File \\\"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_interceptor.py\\\", line 277, in __call__\", \"    response, ignored_call = self._with_call(\", \"                             ^^^^^^^^^^^^^^^^\", \"  File \\\"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_interceptor.py\\\", line 332, in _with_call\", \"    return call.result(), call\", \"           ^^^^^^^^^^^^^\", \"  File \\\"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_channel.py\\\", line 440, in result\", \"    raise self\", \"  File \\\"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_interceptor.py\\\", line 315, in continuation\", \"    response, call = self._thunk(new_method).with_call(\", \"                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\", \"  File \\\"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_channel.py\\\", line 1192, in with_call\", \"    return _end_unary_response_blocking(state, call, True, None)\", \"           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\", \"  File \\\"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_channel.py\\\", line 1006, in _end_unary_response_blocking\", \"    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\", \"    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\", \"grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\", \"\\tstatus = StatusCode.FAILED_PRECONDITION\", \"\\tdetails = \\\"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=3c9af5a3-cdb1-4623-873f-7eeddad92a21, reason=INACTIVITY_TIMEOUT]. (requestId=8039babd-55cc-4fef-9b09-7be0080a1137)\\\"\", \"\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {grpc_status:9, grpc_message:\\\"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=3c9af5a3-cdb1-4623-873f-7eeddad92a21, reason=INACTIVITY_TIMEOUT]. (requestId=8039babd-55cc-4fef-9b09-7be0080a1137)\\\"}\\\"\", \">\"]}}\n",
      "ERROR:pyspark.sql.connect.client.logging:GRPC Error received\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py\", line 2042, in config\n",
      "    resp = self._stub.Config(req, metadata=self.metadata())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_interceptor.py\", line 277, in __call__\n",
      "    response, ignored_call = self._with_call(\n",
      "                             ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_interceptor.py\", line 332, in _with_call\n",
      "    return call.result(), call\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_channel.py\", line 440, in result\n",
      "    raise self\n",
      "  File \"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_interceptor.py\", line 315, in continuation\n",
      "    response, call = self._thunk(new_method).with_call(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_channel.py\", line 1192, in with_call\n",
      "    return _end_unary_response_blocking(state, call, True, None)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/grpc/_channel.py\", line 1006, in _end_unary_response_blocking\n",
      "    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n",
      "\tstatus = StatusCode.FAILED_PRECONDITION\n",
      "\tdetails = \"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=3c9af5a3-cdb1-4623-873f-7eeddad92a21, reason=INACTIVITY_TIMEOUT]. (requestId=8039babd-55cc-4fef-9b09-7be0080a1137)\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_status:9, grpc_message:\"BAD_REQUEST: session_id is no longer usable. Generate a new session_id by detaching and reattaching the compute and then try again [sessionId=3c9af5a3-cdb1-4623-873f-7eeddad92a21, reason=INACTIVITY_TIMEOUT]. (requestId=8039babd-55cc-4fef-9b09-7be0080a1137)\"}\"\n",
      ">\n",
      "/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py:2319: UserWarning: Spark Connect Session expired on the server. Please generate a new session by detaching and reattaching the compute or by calling DatabricksSession.builder.getOrCreate().\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "'/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/data_pipelines/src/mlruns' does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mChain file not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchain_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Log the model to MLflow\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madtech_chat_history_agent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m      9\u001b[39m   logged_chain_info = mlflow.langchain.log_model(\n\u001b[32m     10\u001b[39m           \u001b[38;5;66;03m#Note: In classical ML, MLflow works by serializing the model object.  In generative AI, chains often include Python packages that do not serialize.  Here, we use MLflow's new code-based logging, where we saved our chain under the chain notebook and will use this code instead of trying to serialize the object.\u001b[39;00m\n\u001b[32m     11\u001b[39m           lc_model=os.path.join(os.getcwd(), \u001b[33m'\u001b[39m\u001b[33mchain.py\u001b[39m\u001b[33m'\u001b[39m),  \u001b[38;5;66;03m# Chain code file e.g., /path/to/the/chain.py \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m           ]\n\u001b[32m     20\u001b[39m       )\n\u001b[32m     22\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mchat_history_agent\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/mlflow/tracking/fluent.py:474\u001b[39m, in \u001b[36mstart_run\u001b[39m\u001b[34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[39m\n\u001b[32m    470\u001b[39m         user_specified_tags[MLFLOW_RUN_NAME] = run_name\n\u001b[32m    472\u001b[39m     resolved_tags = context_registry.resolve_tags(user_specified_tags)\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     active_run_obj = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexp_id_for_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolved_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m log_system_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# If `log_system_metrics` is not specified, we will check environment variable.\u001b[39;00m\n\u001b[32m    482\u001b[39m     log_system_metrics = MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING.get()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/mlflow/tracking/client.py:434\u001b[39m, in \u001b[36mMlflowClient.create_run\u001b[39m\u001b[34m(self, experiment_id, start_time, tags, run_name)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_run\u001b[39m(\n\u001b[32m    381\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    382\u001b[39m     experiment_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    385\u001b[39m     run_name: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    386\u001b[39m ) -> Run:\n\u001b[32m    387\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    388\u001b[39m \u001b[33;03m    Create a :py:class:`mlflow.entities.Run` object that can be associated with\u001b[39;00m\n\u001b[32m    389\u001b[39m \u001b[33;03m    metrics, parameters, artifacts, etc.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    432\u001b[39m \u001b[33;03m        status: RUNNING\u001b[39;00m\n\u001b[32m    433\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:161\u001b[39m, in \u001b[36mTrackingServiceClient.create_run\u001b[39m\u001b[34m(self, experiment_id, start_time, tags, run_name)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;66;03m# Extract user from tags\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;66;03m# This logic is temporary; the user_id attribute of runs is deprecated and will be removed\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m# in a later release.\u001b[39;00m\n\u001b[32m    159\u001b[39m user_id = tags.get(MLFLOW_USER, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_current_time_millis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRunTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/mlflow/store/tracking/file_store.py:662\u001b[39m, in \u001b[36mFileStore.create_run\u001b[39m\u001b[34m(self, experiment_id, user_id, start_time, tags, run_name)\u001b[39m\n\u001b[32m    658\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    659\u001b[39m \u001b[33;03mCreates a run with the specified attributes.\u001b[39;00m\n\u001b[32m    660\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    661\u001b[39m experiment_id = FileStore.DEFAULT_EXPERIMENT_ID \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m experiment = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    664\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    665\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not create run under experiment with ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - no such \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    666\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mexperiment exists.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    667\u001b[39m         databricks_pb2.RESOURCE_DOES_NOT_EXIST,\n\u001b[32m    668\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/mlflow/store/tracking/file_store.py:471\u001b[39m, in \u001b[36mFileStore.get_experiment\u001b[39m\u001b[34m(self, experiment_id)\u001b[39m\n\u001b[32m    460\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    461\u001b[39m \u001b[33;03mFetch the experiment.\u001b[39;00m\n\u001b[32m    462\u001b[39m \u001b[33;03mNote: This API will search for active as well as deleted experiments.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    468\u001b[39m \u001b[33;03m    A single Experiment object if it exists, otherwise raises an Exception.\u001b[39;00m\n\u001b[32m    469\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    470\u001b[39m experiment_id = FileStore.DEFAULT_EXPERIMENT_ID \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m experiment = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    474\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExperiment \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m does not exist.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    475\u001b[39m         databricks_pb2.RESOURCE_DOES_NOT_EXIST,\n\u001b[32m    476\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/mlflow/store/tracking/file_store.py:437\u001b[39m, in \u001b[36mFileStore._get_experiment\u001b[39m\u001b[34m(self, experiment_id, view_type)\u001b[39m\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_experiment\u001b[39m(\u001b[38;5;28mself\u001b[39m, experiment_id, view_type=ViewType.ALL):\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_root_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    438\u001b[39m     _validate_experiment_id(experiment_id)\n\u001b[32m    439\u001b[39m     experiment_dir = \u001b[38;5;28mself\u001b[39m._get_experiment_path(experiment_id, view_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/adtech_app_lakebase_vibe_session/.venv/lib/python3.11/site-packages/mlflow/store/tracking/file_store.py:224\u001b[39m, in \u001b[36mFileStore._check_root_dir\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[33;03mRun checks before running directory operations.\u001b[39;00m\n\u001b[32m    222\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists(\u001b[38;5;28mself\u001b[39m.root_directory):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.root_directory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m does not exist.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_directory(\u001b[38;5;28mself\u001b[39m.root_directory):\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.root_directory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not a directory.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mException\u001b[39m: '/Users/tanner.wendland/projects/adtech_app_lakebase_vibe_session/data_pipelines/src/mlruns' does not exist."
     ]
    }
   ],
   "source": [
    "from mlflow.models.resources import DatabricksVectorSearchIndex, DatabricksServingEndpoint\n",
    "\n",
    "chain_file_path = os.path.join(os.getcwd(), 'chain.py')\n",
    "if not os.path.exists(chain_file_path):\n",
    "    raise FileNotFoundError(f\"Chain file not found at {chain_file_path}\")\n",
    "\n",
    "# Log the model to MLflow\n",
    "with mlflow.start_run(run_name=\"adtech_chat_history_agent\"):\n",
    "  logged_chain_info = mlflow.langchain.log_model(\n",
    "          #Note: In classical ML, MLflow works by serializing the model object.  In generative AI, chains often include Python packages that do not serialize.  Here, we use MLflow's new code-based logging, where we saved our chain under the chain notebook and will use this code instead of trying to serialize the object.\n",
    "          lc_model=os.path.join(os.getcwd(), 'chain.py'),  # Chain code file e.g., /path/to/the/chain.py \n",
    "          model_config=chain_config, # Chain configuration \n",
    "          artifact_path=\"chain\", # Required by MLflow, the chain's code/config are saved in this directory\n",
    "          input_example=input_example,\n",
    "          # Specify resources for automatic authentication passthrough\n",
    "          resources=[\n",
    "            DatabricksVectorSearchIndex(index_name=model_config.get(\"vector_search_index\")),\n",
    "            DatabricksServingEndpoint(endpoint_name=model_config.get(\"llm_model_serving_endpoint_name\"))\n",
    "          ]\n",
    "      )\n",
    "\n",
    "model_name = \"chat_history_agent\"\n",
    "MODEL_NAME_FQN = f\"{target_catalog}.{target_schema}.{model_name}\"\n",
    "# Register to UC\n",
    "uc_registered_model_info = mlflow.register_model(model_uri=logged_chain_info.model_uri, name=MODEL_NAME_FQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualy deploy the model to Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import EndpointCoreConfigInput, ServedEntityInput\n",
    "\n",
    "workspace_client = WorkspaceClient()\n",
    "\n",
    "version = uc_registered_model_info.version\n",
    "serving_endpoint_name = MODEL_NAME_FQN.replace(\".\", \"-\")\n",
    "\n",
    "config = {\n",
    "        \"served_entities\": [\n",
    "            {\n",
    "                \"name\": serving_endpoint_name,\n",
    "                \"entity_name\": MODEL_NAME_FQN,\n",
    "                \"entity_version\": version,\n",
    "                \"workload_size\": \"Small\",\n",
    "                \"scale_to_zero_enabled\": True,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def does_endpoint_exists(endpoint_name):\n",
    "    try:\n",
    "        workspace_client.serving_endpoints.get(endpoint_name)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "if not does_endpoint_exists(serving_endpoint_name):\n",
    "    print(f\"Creating endpoint {serving_endpoint_name}...\")\n",
    "    workspace_client.serving_endpoints.create_and_wait(\n",
    "        serving_endpoint_name,\n",
    "        config=EndpointCoreConfigInput.from_dict(config)\n",
    "    )\n",
    "else:\n",
    "    print(f\"Updating endpoint {serving_endpoint_name}...\")\n",
    "    workspace_client.serving_endpoints.update_config_and_wait(\n",
    "        serving_endpoint_name,\n",
    "        served_entities=[ServedEntityInput.from_dict(entity) for entity in config['served_entities']]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
