{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cf63ecd-9099-40b4-aa3a-0700f2576e5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: databricks-sdk==0.61.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (0.61.0)\n",
      "Requirement already satisfied: pyarrow<20 in /databricks/python3/lib/python3.11/site-packages (14.0.1)\n",
      "Requirement already satisfied: databricks-agents==1.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: mlflow<=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (3.1.0)\n",
      "Requirement already satisfied: databricks-vectorsearch==0.57 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (0.57)\n",
      "Requirement already satisfied: langchain==0.3.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-mcp in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (0.2.1)\n",
      "Requirement already satisfied: langchain_core==0.3.74 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (0.3.74)\n",
      "Requirement already satisfied: databricks-langchain==0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (0.7.0)\n",
      "Requirement already satisfied: bs4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (0.0.2)\n",
      "Requirement already satisfied: dotenv in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (0.9.9)\n",
      "Requirement already satisfied: psycopg2-binary==2.9.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (2.9.7)\n",
      "Requirement already satisfied: pgvector==0.2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (0.2.5)\n",
      "Requirement already satisfied: langgraph==0.3.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (0.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.28.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-sdk==0.61.0) (2.32.5)\n",
      "Requirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk==0.61.0) (2.35.0)\n",
      "Requirement already satisfied: databricks-connect in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-agents==1.2.0) (16.1.6)\n",
      "Requirement already satisfied: dataclasses-json in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-agents==1.2.0) (0.6.7)\n",
      "Requirement already satisfied: jinja2>=3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-agents==1.2.0) (3.1.6)\n",
      "Requirement already satisfied: mlflow-skinny<4.0.0,>=3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-agents==1.2.0) (3.1.0)\n",
      "Requirement already satisfied: tenacity>=8.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-agents==1.2.0) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-agents==1.2.0) (0.11.0)\n",
      "Requirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-agents==1.2.0) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-agents==1.2.0) (2.0.7)\n",
      "Requirement already satisfied: pydantic>=2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-agents==1.2.0) (2.11.7)\n",
      "Requirement already satisfied: whenever==0.7.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-agents==1.2.0) (0.7.3)\n",
      "Requirement already satisfied: boto3>1 in /databricks/python3/lib/python3.11/site-packages (from databricks-agents==1.2.0) (1.34.39)\n",
      "Requirement already satisfied: botocore in /databricks/python3/lib/python3.11/site-packages (from databricks-agents==1.2.0) (1.34.39)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-vectorsearch==0.57) (4.25.8)\n",
      "Requirement already satisfied: deprecation>=2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-vectorsearch==0.57) (2.1.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from langchain==0.3.27) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from langchain==0.3.27) (0.4.19)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from langchain==0.3.27) (2.0.43)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.11/site-packages (from langchain==0.3.27) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from langchain_core==0.3.74) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from langchain_core==0.3.74) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /databricks/python3/lib/python3.11/site-packages (from langchain_core==0.3.74) (23.2)\n",
      "Requirement already satisfied: databricks-ai-bridge>=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-langchain==0.7.0) (0.7.1)\n",
      "Requirement already satisfied: openai>=1.99.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-langchain==0.7.0) (1.102.0)\n",
      "Requirement already satisfied: unitycatalog-langchain>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain==0.7.0) (0.2.0)\n",
      "Requirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from pgvector==0.2.5) (1.26.4)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from langgraph==0.3.4) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from langgraph==0.3.4) (0.1.8)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from langgraph==0.3.4) (0.1.74)\n",
      "Requirement already satisfied: ipython<10,>=8 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk[notebook]) (8.25.0)\n",
      "Requirement already satisfied: ipywidgets<9,>=8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-sdk[notebook]) (8.1.7)\n",
      "Requirement already satisfied: Flask<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mlflow<=3.1) (3.1.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mlflow<=3.1) (1.16.5)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mlflow<=3.1) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mlflow<=3.1) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mlflow<=3.1) (23.0.0)\n",
      "Requirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow<=3.1) (3.7.2)\n",
      "Requirement already satisfied: pandas<3 in /databricks/python3/lib/python3.11/site-packages (from mlflow<=3.1) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow<=3.1) (1.3.0)\n",
      "Requirement already satisfied: scipy<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow<=3.1) (1.11.1)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (3.0.0)\n",
      "Requirement already satisfied: fastapi<1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (0.116.1)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (3.1.43)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (6.0.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (1.36.0)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (0.5.1)\n",
      "Requirement already satisfied: uvicorn<1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (0.35.0)\n",
      "Requirement already satisfied: azure-storage-file-datalake>12 in /databricks/python3/lib/python3.11/site-packages (from mlflow[databricks]) (12.14.0)\n",
      "Requirement already satisfied: google-cloud-storage>=1.30.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow[databricks]) (2.18.2)\n",
      "Requirement already satisfied: mcp~=1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from langchain-mcp) (1.13.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from bs4) (4.13.5)\n",
      "Requirement already satisfied: python-dotenv in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from dotenv) (1.1.1)\n",
      "Requirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow<=3.1) (1.3.10)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow[databricks]) (1.32.0)\n",
      "Requirement already satisfied: azure-storage-blob<13.0.0,>=12.19.0 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow[databricks]) (12.19.1)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow[databricks]) (0.7.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.11/site-packages (from boto3>1->databricks-agents==1.2.0) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /databricks/python3/lib/python3.11/site-packages (from boto3>1->databricks-agents==1.2.0) (0.10.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /databricks/python3/lib/python3.11/site-packages (from botocore->databricks-agents==1.2.0) (2.8.2)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-ai-bridge>=0.7.0->databricks-langchain==0.7.0) (0.9.0)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.56.4 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect->databricks-agents==1.2.0) (1.65.0)\n",
      "Requirement already satisfied: grpcio-status>=1.59.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-connect->databricks-agents==1.2.0) (1.62.3)\n",
      "Requirement already satisfied: grpcio>=1.59.3 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect->databricks-agents==1.2.0) (1.69.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect->databricks-agents==1.2.0) (0.10.9.7)\n",
      "Requirement already satisfied: setuptools>=68.0.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect->databricks-agents==1.2.0) (75.1.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from databricks-connect->databricks-agents==1.2.0) (1.16.0)\n",
      "Requirement already satisfied: langchain-openai in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-sdk[openai]>=0.58.0->databricks-agents==1.2.0) (0.3.32)\n",
      "Requirement already satisfied: httpx in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from databricks-sdk[openai]>=0.58.0->databricks-agents==1.2.0) (0.28.1)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from Flask<4->mlflow<=3.1) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from Flask<4->mlflow<=3.1) (2.2.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from Flask<4->mlflow<=3.1) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from Flask<4->mlflow<=3.1) (3.1.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk==0.61.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk==0.61.0) (4.9)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]) (2.18.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]) (1.6.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from graphene<4->mlflow<=3.1) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from graphene<4->mlflow<=3.1) (3.2.0)\n",
      "Requirement already satisfied: decorator in /databricks/python3/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /databricks/python3/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /databricks/python3/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /databricks/python3/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /databricks/python3/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /databricks/python3/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /databricks/python3/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (5.13.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /databricks/python3/lib/python3.11/site-packages (from ipython<10,>=8->databricks-sdk[notebook]) (4.8.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from ipywidgets<9,>=8->databricks-sdk[notebook]) (0.2.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from ipywidgets<9,>=8->databricks-sdk[notebook]) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from ipywidgets<9,>=8->databricks-sdk[notebook]) (3.0.15)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain_core==0.3.74) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph==0.3.4) (1.10.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.3.4) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /databricks/python3/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow<=3.1) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow<=3.1) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow<=3.1) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow<=3.1) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow<=3.1) (10.3.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow<=3.1) (3.0.9)\n",
      "Requirement already satisfied: anyio>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mcp~=1.0->langchain-mcp) (4.10.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mcp~=1.0->langchain-mcp) (0.4.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mcp~=1.0->langchain-mcp) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mcp~=1.0->langchain-mcp) (2.10.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mcp~=1.0->langchain-mcp) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mcp~=1.0->langchain-mcp) (3.0.2)\n",
      "Requirement already satisfied: starlette>=0.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from mcp~=1.0->langchain-mcp) (0.47.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.99.9->databricks-langchain==0.7.0) (1.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from openai>=1.99.9->databricks-langchain==0.7.0) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from openai>=1.99.9->databricks-langchain==0.7.0) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas<3->mlflow<=3.1) (2022.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from pydantic>=2->databricks-agents==1.2.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from pydantic>=2->databricks-agents==1.2.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from pydantic>=2->databricks-agents==1.2.0) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk==0.61.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk==0.61.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.28.1->databricks-sdk==0.61.0) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow<=3.1) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow<=3.1) (2.2.0)\n",
      "Requirement already satisfied: greenlet>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from tiktoken>=0.8.0->databricks-agents==1.2.0) (2025.7.34)\n",
      "Requirement already satisfied: langchain-community>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain==0.7.0) (0.3.28)\n",
      "Requirement already satisfied: unitycatalog-ai in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain==0.7.0) (0.3.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from beautifulsoup4->bs4) (2.8)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from dataclasses-json->databricks-agents==1.2.0) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from dataclasses-json->databricks-agents==1.2.0) (0.9.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow[databricks]) (41.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (4.0.11)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /databricks/python3/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=1.30.0->mlflow[databricks]) (1.25.0)\n",
      "Requirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from httpx->databricks-sdk[openai]>=0.58.0->databricks-agents==1.2.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from httpcore==1.*->httpx->databricks-sdk[openai]>=0.58.0->databricks-agents==1.2.0) (0.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (3.11.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /databricks/python3/lib/python3.11/site-packages (from jedi>=0.16->ipython<10,>=8->databricks-sdk[notebook]) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp~=1.0->langchain-mcp) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp~=1.0->langchain-mcp) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp~=1.0->langchain-mcp) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp~=1.0->langchain-mcp) (0.27.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain==0.7.0) (3.12.15)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (0.57b0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /databricks/python3/lib/python3.11/site-packages (from pexpect>4.3->ipython<10,>=8->databricks-sdk[notebook]) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /databricks/python3/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython<10,>=8->databricks-sdk[notebook]) (0.2.5)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk==0.61.0) (0.4.8)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->databricks-agents==1.2.0) (0.4.3)\n",
      "Requirement already satisfied: executing in /databricks/python3/lib/python3.11/site-packages (from stack-data->ipython<10,>=8->databricks-sdk[notebook]) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /databricks/python3/lib/python3.11/site-packages (from stack-data->ipython<10,>=8->databricks-sdk[notebook]) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /databricks/python3/lib/python3.11/site-packages (from stack-data->ipython<10,>=8->databricks-sdk[notebook]) (0.2.2)\n",
      "Requirement already satisfied: nest-asyncio in /databricks/python3/lib/python3.11/site-packages (from unitycatalog-ai->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain==0.7.0) (1.5.6)\n",
      "Requirement already satisfied: unitycatalog-client in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from unitycatalog-ai->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain==0.7.0) (0.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain==0.7.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain==0.7.0) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain==0.7.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain==0.7.0) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain==0.7.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain==0.7.0) (1.20.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.11/site-packages (from cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow[databricks]) (1.15.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny<4.0.0,>=3.1.0->databricks-agents==1.2.0) (5.0.1)\n",
      "Requirement already satisfied: aiohttp-retry>=2.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f0af65e9-a326-405a-9539-fca50590544c/lib/python3.11/site-packages (from unitycatalog-client->unitycatalog-ai->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain==0.7.0) (2.9.1)\n",
      "Requirement already satisfied: pycparser in /databricks/python3/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow[databricks]) (2.21)\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install 'databricks-sdk==0.61.0' 'pyarrow<20' 'databricks-sdk[notebook]' 'databricks-agents==1.2.0' 'mlflow<=3.1' 'mlflow[databricks]' 'databricks-vectorsearch==0.57' 'langchain==0.3.27' 'langchain-mcp' 'langchain_core==0.3.74' 'databricks-langchain==0.7.0' 'bs4' 'dotenv' 'psycopg2-binary==2.9.7' 'pgvector==0.2.5' 'langgraph==0.3.4'\n",
    "import os\n",
    "if os.environ.get(\"DATABRICKS_RUNTIME_VERSION\"):\n",
    "    dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aed6b4a-e10c-4d2f-9359-bddb7e481a92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chain_postgres_genie.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chain_postgres_genie.py\n",
    "import functools\n",
    "import os\n",
    "import uuid\n",
    "from typing import Any, Generator, Literal, Optional, Dict, List\n",
    "\n",
    "import mlflow\n",
    "import pydantic\n",
    "from mlflow.models import ModelConfig\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    UCFunctionToolkit,\n",
    "    DatabricksFunctionClient,\n",
    "    set_uc_function_client\n",
    ")\n",
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client) \n",
    "from databricks_langchain.genie import GenieAgent\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "from pydantic import BaseModel\n",
    "from sqlalchemy import create_engine, text, event\n",
    "from pgvector.psycopg2 import register_vector\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_langchain import DatabricksEmbeddings\n",
    "from databricks_langchain.chat_models import ChatDatabricks\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from mlflow.entities import SpanType, Document\n",
    "\n",
    "# Enable MLflow Tracing for LangChain\n",
    "mlflow.autolog()\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "# Load chain configuration provided at logging/deployment time.\n",
    "model_config: ModelConfig = mlflow.models.ModelConfig()\n",
    "\n",
    "# Pydantic models for input validation\n",
    "class Message(pydantic.BaseModel):\n",
    "    role: str\n",
    "    content: str\n",
    "    name: Optional[str] = None\n",
    "\n",
    "class Filters(pydantic.BaseModel):\n",
    "    user_name: str  # Required\n",
    "    chat_id: Optional[str] = None\n",
    "\n",
    "class CustomInputs(pydantic.BaseModel):\n",
    "    filters: Filters\n",
    "    k: Optional[int] = None  # Optional, will default to model_config value\n",
    "\n",
    "class ChatRequest(pydantic.BaseModel):\n",
    "    messages: List[Message]\n",
    "    custom_inputs: Optional[CustomInputs] = None\n",
    "\n",
    "class ChatResponse(pydantic.BaseModel):\n",
    "    messages: List[Message]\n",
    "    finish_reason: Optional[str] = None\n",
    "\n",
    "\n",
    "def _get_required_env(name: str) -> str:\n",
    "    value = os.environ.get(name)\n",
    "    if not value:\n",
    "        raise RuntimeError(f\"Missing required environment variable: {name}\")\n",
    "    return value\n",
    "\n",
    "\n",
    "def get_postgres_connection(\n",
    "    client: WorkspaceClient,\n",
    "    db_instance_name: str,\n",
    "    database_name: Optional[str] = \"databricks_postgres\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build a PostgreSQL SQLAlchemy URL (psycopg2) using Databricks Database credentials.\n",
    "\n",
    "    Uses POSTGRES_GROUP env var as username if set; otherwise current user.\n",
    "    Always enforces sslmode=require.\n",
    "    \"\"\"\n",
    "    database = client.database.get_database_instance(db_instance_name)\n",
    "    credentials = client.database.generate_database_credential(\n",
    "        instance_names=[db_instance_name], request_id=str(uuid.uuid4())\n",
    "    )\n",
    "\n",
    "    postgres_group = os.getenv(\"POSTGRES_GROUP\")\n",
    "    username = (\n",
    "        postgres_group if postgres_group else client.current_user.me().user_name\n",
    "    )\n",
    "\n",
    "    host = database.read_write_dns\n",
    "    port = \"5432\"\n",
    "    password = credentials.token\n",
    "    db_name = database_name or \"databricks_postgres\"\n",
    "\n",
    "    # SQLAlchemy URL with psycopg2 driver\n",
    "    sqlalchemy_url = (\n",
    "        f\"postgresql+psycopg2://{username}:{password}@{host}:{port}/{db_name}?sslmode=require\"\n",
    "    )\n",
    "    return sqlalchemy_url\n",
    "\n",
    "\n",
    "# --- Databricks Auth (required for both embeddings and DB credentials) ---\n",
    "_DATABRICKS_HOST = _get_required_env(\"DATABRICKS_HOST\")\n",
    "_DATABRICKS_TOKEN = _get_required_env(\"DATABRICKS_TOKEN\")\n",
    "\n",
    "workspace_client = WorkspaceClient(host=_DATABRICKS_HOST, token=_DATABRICKS_TOKEN)\n",
    "\n",
    "\n",
    "# --- Postgres Engine (pgvector) ---\n",
    "def _build_engine() -> Any:\n",
    "    # Allow configuration via model_config or environment variables\n",
    "    db_instance_name = (\n",
    "        os.environ.get(\"DATABASE_INSTANCE_NAME\")\n",
    "        or model_config.get(\"database_instance_name\")\n",
    "    )\n",
    "    if not db_instance_name:\n",
    "        raise RuntimeError(\n",
    "            \"A Postgres database instance name is required. Set env 'DATABASE_INSTANCE_NAME' \"\n",
    "            \"or include 'database_instance_name' in the model_config.\"\n",
    "        )\n",
    "\n",
    "    postgres_database_name = (\n",
    "        os.environ.get(\"POSTGRES_DATABASE_NAME\")\n",
    "        or model_config.get(\"postgres_database_name\")\n",
    "        or \"databricks_postgres\"\n",
    "    )\n",
    "\n",
    "    database_url = get_postgres_connection(\n",
    "        workspace_client, db_instance_name, postgres_database_name\n",
    "    )\n",
    "\n",
    "    engine = create_engine(database_url, pool_pre_ping=True)\n",
    "\n",
    "    @event.listens_for(engine, \"connect\")\n",
    "    def _register_vector(dbapi_connection, connection_record):  # noqa: ANN001\n",
    "        # Map Python lists to pgvector type for psycopg2\n",
    "        register_vector(dbapi_connection)\n",
    "\n",
    "    return engine\n",
    "\n",
    "\n",
    "engine = _build_engine()\n",
    "\n",
    "\n",
    "# --- Embeddings ---\n",
    "embeddings = DatabricksEmbeddings(\n",
    "    endpoint=model_config.get(\"embedding_model\"),\n",
    "    token=_DATABRICKS_TOKEN,\n",
    ")\n",
    "\n",
    "# --- Vector similarity search over Postgres (pgvector) ---\n",
    "@mlflow.trace\n",
    "def pg_vector_similarity_search(\n",
    "    query_text: str,\n",
    "    k: int = 3,\n",
    "    filters: Optional[Dict[str, Any]] = None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Perform similarity search against message embeddings in Postgres (pgvector).\n",
    "\n",
    "    Schema expectations:\n",
    "    - message_embeddings(me: id, message_id, user_name, chat_id, embedding vector)\n",
    "    - chat_history(ch: id, message_content, message_type, created_at, message_order)\n",
    "    \"\"\"\n",
    "    filters = filters or {}\n",
    "\n",
    "    # 1) Embed the query\n",
    "    query_embedding = embeddings.embed_query(query_text)\n",
    "\n",
    "    # 2) WHERE clause from filters\n",
    "    where_conditions: List[str] = []\n",
    "    params: Dict[str, Any] = {}\n",
    "\n",
    "    if \"user_name\" in filters:\n",
    "        where_conditions.append(\"me.user_name = :user_name\")\n",
    "        params[\"user_name\"] = filters[\"user_name\"]\n",
    "\n",
    "    where_clause = \"\"\n",
    "    if where_conditions:\n",
    "        where_clause = \"WHERE \" + \" AND \".join(where_conditions)\n",
    "\n",
    "    # 3) Query using cosine distance operator (<=>) provided by pgvector\n",
    "    sql = text(\n",
    "        f\"\"\"\n",
    "        SELECT\n",
    "            ch.message_content,\n",
    "            me.user_name,\n",
    "            me.chat_id,\n",
    "            ch.message_type,\n",
    "            ch.created_at,\n",
    "            ch.message_order,\n",
    "            (me.embedding <=> CAST(:query_embedding AS vector)) AS distance\n",
    "        FROM message_embeddings me\n",
    "        JOIN chat_history ch ON me.message_id = ch.id\n",
    "        {where_clause}\n",
    "        ORDER BY me.embedding <=> CAST(:query_embedding AS vector)\n",
    "        LIMIT :k\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    span = mlflow.get_current_active_span()\n",
    "    span.set_outputs([Document(page_content=sql)])\n",
    "\n",
    "    with engine.connect() as conn:\n",
    "        rows = conn.execute(\n",
    "            sql, {\"query_embedding\": query_embedding, \"k\": k, **params}\n",
    "        ).fetchall()\n",
    "\n",
    "    passages = [f\"Passage: {r.message_content}\" for r in rows]\n",
    "    return \"\\n\".join(passages)\n",
    "  \n",
    "\n",
    "def create_context_aware_vector_search_tool(state, custom_k: Optional[int] = None):\n",
    "    \"\"\"Create a vector search tool that has access to user context from state\"\"\"\n",
    "    \n",
    "    def filtered_vector_search(query: str) -> str:\n",
    "        # Extract user context from state\n",
    "        user_context = state.get(\"user_context\", {})\n",
    "        filters = user_context.get(\"filters\", {})\n",
    "        \n",
    "        # Use custom k if provided, otherwise fall back to model_config default\n",
    "        k = custom_k if custom_k is not None else model_config.get('k')\n",
    "        \n",
    "        # Use your existing pg_vector_similarity_search with filters and custom k\n",
    "        return pg_vector_similarity_search(\n",
    "            query_text=query, \n",
    "            k=k, \n",
    "            filters=filters\n",
    "        )\n",
    "    \n",
    "    return Tool(\n",
    "        name=\"search_chat_history\",\n",
    "        description=\"Retrieve chat history from Postgres (pgvector) for the current user; use only if the immediate conversation context is insufficient. The input to this function should be the user message.\",\n",
    "        func=filtered_vector_search,\n",
    "    )\n",
    "\n",
    "\n",
    "genie_agent_description = model_config.get('genie_agent_description')\n",
    "general_assistant_description = model_config.get('general_assistant_description')\n",
    "code_agent_description = model_config.get('code_agent_description')\n",
    "\n",
    "genie_agent = GenieAgent(\n",
    "    genie_space_id=model_config.get('genie_space_id'),\n",
    "    genie_agent_name=\"Genie\",\n",
    "    description=genie_agent_description,\n",
    "    client=workspace_client,\n",
    "    include_context=True,\n",
    ")\n",
    "\n",
    "# Max number of interactions between agents\n",
    "MAX_ITERATIONS = 3\n",
    "\n",
    "worker_descriptions = {\n",
    "    \"Genie\": genie_agent_description,\n",
    "    \"General\": general_assistant_description,\n",
    "    \"Coder\": code_agent_description,\n",
    "}\n",
    "\n",
    "formatted_descriptions = \"\\n\".join(\n",
    "    f\"- {name}: {desc}\" for name, desc in worker_descriptions.items()\n",
    ")\n",
    "\n",
    "system_prompt = f\"Decide between routing between the following workers or ending the conversation if an answer is provided. \\n{formatted_descriptions}\"\n",
    "options = [\"FINISH\"] + list(worker_descriptions.keys())\n",
    "FINISH = {\"next_node\": \"FINISH\"}\n",
    "\n",
    "# Our foundation model answering the final prompt\n",
    "model = ChatDatabricks(\n",
    "    endpoint=model_config.get(\"llm_model_serving_endpoint_name\"),\n",
    "    extra_params={\"temperature\": 0.01, \"max_tokens\": 500}\n",
    ")\n",
    "\n",
    "# Custom Static Tools\n",
    "tools = []\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    count = state.get(\"iteration_count\", 0) + 1\n",
    "    if count > MAX_ITERATIONS:\n",
    "        return FINISH\n",
    "    \n",
    "    class nextNode(BaseModel):\n",
    "        next_node: Literal[tuple(options)]\n",
    "\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    )\n",
    "    supervisor_chain = preprocessor | model.with_structured_output(nextNode)\n",
    "    next_node = supervisor_chain.invoke(state).next_node\n",
    "    \n",
    "    # if routed back to the same node, exit the loop\n",
    "    if state.get(\"next_node\") == next_node:\n",
    "        return FINISH\n",
    "    return {\n",
    "        \"iteration_count\": count,\n",
    "        \"next_node\": next_node\n",
    "    }\n",
    "\n",
    "#######################################\n",
    "# Define our multiagent graph structure\n",
    "#######################################\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": result[\"messages\"][-1].content,\n",
    "                \"name\": name,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def final_answer(state):\n",
    "    prompt = \"Using only the content in the messages, respond to the previous user question using the answer given by the other assistant messages.\"\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: state[\"messages\"] + [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    final_answer_chain = preprocessor | model\n",
    "    return {\"messages\": [final_answer_chain.invoke(state)]}\n",
    "\n",
    "\n",
    "def agent_node_with_context(state, agent, name, custom_k: Optional[int] = None):\n",
    "    \"\"\"Enhanced agent node that injects context-aware tools\"\"\"\n",
    "    \n",
    "    # Create the shared vector search tool with current state context and custom k\n",
    "    vector_search_tool = create_context_aware_vector_search_tool(state, custom_k)\n",
    "    \n",
    "    if name == \"Genie\":\n",
    "        # Genie already has its tools, just add vector search\n",
    "        enhanced_agent = agent  # Genie agent already configured\n",
    "        \n",
    "    elif name == \"Coder\" or name == \"General\":\n",
    "        # Add vector search tool to other agents' tools\n",
    "        enhanced_tools = tools + [vector_search_tool]\n",
    "        enhanced_agent = create_react_agent(model, tools=enhanced_tools)\n",
    "        \n",
    "    # Execute with enhanced agent\n",
    "    result = enhanced_agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [{\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": result[\"messages\"][-1].content,\n",
    "            \"name\": name,\n",
    "        }]\n",
    "    }\n",
    "\n",
    "class AgentState(ChatAgentState):\n",
    "    next_node: str\n",
    "    iteration_count: int\n",
    "    user_context: Optional[Dict[str, Any]] = None\n",
    "    custom_k: Optional[int] = None\n",
    "\n",
    "# Create enhanced agent nodes\n",
    "def enhanced_genie_node(state):\n",
    "    custom_k = state.get(\"custom_k\")\n",
    "    return agent_node_with_context(state, genie_agent, \"Genie\", custom_k)\n",
    "\n",
    "def enhanced_coder_node(state):\n",
    "    custom_k = state.get(\"custom_k\")\n",
    "    return agent_node_with_context(state, None, \"Coder\", custom_k)\n",
    "\n",
    "def enhanced_general_node(state):\n",
    "    custom_k = state.get(\"custom_k\")\n",
    "    return agent_node_with_context(state, None, \"General\", custom_k)\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "# Agent States\n",
    "workflow.add_node(\"Genie\", enhanced_genie_node)\n",
    "workflow.add_node(\"Coder\", enhanced_coder_node)\n",
    "workflow.add_node(\"General\", enhanced_general_node)\n",
    "# Supervisor States\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "workflow.add_node(\"final_answer\", final_answer)\n",
    "\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "# We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "for worker in worker_descriptions.keys():\n",
    "    workflow.add_edge(worker, \"supervisor\")\n",
    "\n",
    "# Let the supervisor decide which next node to go\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next_node\"],\n",
    "    {**{k: k for k in worker_descriptions.keys()}, \"FINISH\": \"final_answer\"},\n",
    ")\n",
    "workflow.add_edge(\"final_answer\", END)\n",
    "multi_agent = workflow.compile()\n",
    "\n",
    "###################################\n",
    "# Pydantic-based PythonModel\n",
    "###################################\n",
    "\n",
    "class ChatAgentPythonModel(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self):\n",
    "        self.agent = multi_agent\n",
    "        \n",
    "    def predict(self, context, model_input: List[ChatRequest]) -> List[ChatResponse]:\n",
    "        \"\"\"\n",
    "        Predict method with pydantic type hints for automatic schema generation.\n",
    "        Note: MLflow expects List[InputType] -> List[OutputType] for pyfunc models.\n",
    "        \"\"\"\n",
    "        responses = []\n",
    "        \n",
    "        for request in model_input:\n",
    "            # Extract user context from request\n",
    "            user_context = {}\n",
    "            custom_k = None\n",
    "            \n",
    "            if request.custom_inputs:\n",
    "                user_context[\"filters\"] = request.custom_inputs.filters.model_dump()\n",
    "                custom_k = request.custom_inputs.k\n",
    "            \n",
    "            # Convert pydantic messages to dict format for langgraph\n",
    "            messages_dict = [msg.model_dump(exclude_none=True) for msg in request.messages]\n",
    "            \n",
    "            agent_request = {\n",
    "                \"messages\": messages_dict,\n",
    "                \"user_context\": user_context,\n",
    "                \"custom_k\": custom_k\n",
    "            }\n",
    "\n",
    "            response_messages = []\n",
    "            for event in self.agent.stream(agent_request, stream_mode=\"updates\"):\n",
    "                for node_data in event.values():\n",
    "                    for msg in node_data.get(\"messages\", []):\n",
    "                        response_messages.append(Message(**msg))\n",
    "            \n",
    "            responses.append(ChatResponse(messages=response_messages))\n",
    "        \n",
    "        return responses\n",
    "\n",
    "# Create the model instance and set it for MLflow\n",
    "model_instance = ChatAgentPythonModel()\n",
    "mlflow.models.set_model(model=model_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "354c76a9-8be0-4c8d-9983-9e57eb961e82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"embedding_model\", \"databricks-gte-large-en\")\n",
    "dbutils.widgets.text(\"database_instance_name\", \"tannerw-adtech-db\")\n",
    "dbutils.widgets.text(\"postgres_database_name\", \"databricks_postgres\")\n",
    "dbutils.widgets.text(\"llm_model_serving_endpoint_name\", \"databricks-claude-3-7-sonnet\")\n",
    "dbutils.widgets.text(\"target_catalog\", \"tanner_wendland\")\n",
    "dbutils.widgets.text(\"target_schema\", \"default\")\n",
    "dbutils.widgets.text(\"genie_space_id\", \"01efcca6fdc712d7be87a40ad4a2e33e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c99bd51e-5492-4d5d-a971-0ddda14452cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "embedding_model = dbutils.widgets.get(\"embedding_model\")\n",
    "database_instance_name = dbutils.widgets.get(\"database_instance_name\")\n",
    "postgres_database_name = dbutils.widgets.get(\"postgres_database_name\")\n",
    "llm_model_serving_endpoint_name = dbutils.widgets.get(\"llm_model_serving_endpoint_name\")\n",
    "target_catalog = dbutils.widgets.get(\"target_catalog\")\n",
    "target_schema = dbutils.widgets.get(\"target_schema\")\n",
    "genie_space_id = dbutils.widgets.get(\"genie_space_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2750086a-7c5b-40aa-b5f6-28fec9147b79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "from typing import Any, Generator, Literal, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d115d39-47b3-40a6-b143-e4ae3f30c1c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow.autolog()\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "585760d5-cc0a-4a30-b069-1b57188e8623",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Chain Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff9d15d1-397a-4cdf-b948-41a6ad5555f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chain_config = {\n",
    "    \"llm_model_serving_endpoint_name\": llm_model_serving_endpoint_name,\n",
    "    \"embedding_model\": embedding_model,\n",
    "    \"database_instance_name\": database_instance_name,\n",
    "    \"postgres_database_name\": postgres_database_name,\n",
    "    \"genie_space_id\": genie_space_id,\n",
    "    \"k\": 3,\n",
    "    \"genie_agent_description\": \"You are a an agent that can invoke Genie, a powerful text-to-sql database assistant. You can use this tool to answer questions related to sales pipelines.\",\n",
    "    \"general_assistant_description\": \"The General Assistant agent is a helpful assistant that can answer any question.\",\n",
    "    \"code_agent_description\": \"The Coder agent specializes in solving programming challenges, generating code snippets, debugging issues, and explaining complex coding concepts.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "247bc64a-7331-4a60-97fe-52d0360bd338",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Chain PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e706a3d-0b01-44e6-95e1-fcaa22ffaf44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/28 15:51:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      " View Logged Model at: https://e2-demo-field-eng.cloud.databricks.com/ml/experiments/267633790734116/models/m-42dfde67641444cb8f606ff788bb2c01?o=1444828305810485\n",
      "2025/08/28 15:51:42 INFO mlflow.models.signature: Running the predict function to generate output based on input example\n",
      "2025/08/28 15:52:11 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "Registered model 'tanner_wendland.default.chat_history_agent_postgres_genie' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bec73a453146abb6cc6e381e102201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10015ab67b914c13b7d38e77273b5b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Created version '23' of model 'tanner_wendland.default.chat_history_agent_postgres_genie': https://e2-demo-field-eng.cloud.databricks.com/explore/data/models/tanner_wendland/default/chat_history_agent_postgres_genie/version/23?o=1444828305810485\n"
     ]
    }
   ],
   "source": [
    "from mlflow.models.resources import DatabricksVectorSearchIndex, DatabricksServingEndpoint, DatabricksGenieSpace\n",
    "\n",
    "chain_file_path = os.path.join(os.getcwd(), 'chain_postgres_genie.py')\n",
    "if not os.path.exists(chain_file_path):\n",
    "    raise FileNotFoundError(f\"Chain file not found at {chain_file_path}\")\n",
    "\n",
    "workspace_url = spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
    "os.environ['DATABRICKS_HOST'] = f\"https://{workspace_url}\"\n",
    "os.environ['DATABRICKS_TOKEN'] = dbutils.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "# Pydantic-based input example - schema will be auto-inferred from type hints\n",
    "# Note: MLflow pyfunc expects List[InputType], so wrap in a list\n",
    "input_example = [\n",
    "    {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"What was my chat history idea?\"}],\n",
    "        # No custom_inputs to keep it optional\n",
    "    }\n",
    "]\n",
    "\n",
    "model_config = mlflow.models.ModelConfig(development_config=chain_config)\n",
    "\n",
    "# Use pyfunc log_model with the file path (models-from-code approach)\n",
    "with mlflow.start_run(run_name=\"adtech_chat_history_agent_postgres_genie_pydantic\"):\n",
    "    logged_chain_info = mlflow.pyfunc.log_model(\n",
    "        python_model=chain_file_path,  # Path to the chain file\n",
    "        model_config=chain_config,\n",
    "        artifact_path=\"chat_agent_pydantic\",\n",
    "        input_example=input_example,  # Schema auto-inferred from List[ChatRequest] type hint\n",
    "        # Specify resources for automatic authentication passthrough\n",
    "        resources=[\n",
    "            DatabricksServingEndpoint(endpoint_name=model_config.get(\"llm_model_serving_endpoint_name\")),\n",
    "            DatabricksGenieSpace(genie_space_id=model_config.get(\"genie_space_id\"))\n",
    "        ],\n",
    "        pip_requirements=[\n",
    "            \"mlflow==3.1.0\",\n",
    "            \"databricks-agents==1.2.0\", \n",
    "            \"databricks-langchain==0.7.0\",\n",
    "            \"langchain==0.3.27\",\n",
    "            \"pgvector==0.2.5\",\n",
    "            \"psycopg2-binary==2.9.7\",\n",
    "            \"pydantic==2.11.7\",\n",
    "            \"sqlalchemy==2.0.43\",\n",
    "            \"tornado==6.3.2\",\n",
    "            \"langgraph==0.3.4\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model_name = \"chat_history_agent_postgres_genie\"\n",
    "MODEL_NAME_FQN = f\"{target_catalog}.{target_schema}.{model_name}\"\n",
    "# Register to UC\n",
    "uc_registered_model_info = mlflow.register_model(model_uri=logged_chain_info.model_uri, name=MODEL_NAME_FQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7d1e4f2-7b64-4eb4-97af-4f10df379539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2489771f4f4037a96dc1cc672a9ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AGENT = mlflow.pyfunc.load_model(logged_chain_info.model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4a985e5-e27b-41c8-a705-82ed8d1ebb9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test Document Retreival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b3300a0-9b8e-40a5-a8fd-fd3ae12ca393",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test with custom k=10 ===\n",
      "[ChatResponse(messages=[Message(role='assistant', content=\"I apologize, but I'm experiencing a technical issue accessing the chat history database. It seems there might be a connection problem with the database service.\\n\\nWithout access to your previous conversations, I don't have context about any specific chat history idea you mentioned before. Could you please provide more details about the idea you're referring to? This would help me better assist you with your question.\", name='General'), Message(role='assistant', content=\"I don't see any previous messages from other assistants in our current conversation that contain information about your chat history idea. Our conversation only includes your initial question asking about your chat history idea, my response explaining I couldn't access previous conversations, and your most recent instruction.\\n\\nWithout any other assistant messages or additional context in our current conversation thread, I don't have information about what your chat history idea was.\", name=None)], finish_reason=None)]\n",
      "\n",
      "=== Test with no custom_inputs (should use defaults) ===\n",
      "[ChatResponse(messages=[Message(role='assistant', content=\"I apologize, but I'm experiencing a technical issue when trying to access your chat history. The database connection that would allow me to retrieve your previous conversations isn't working properly at the moment.\\n\\nTo help you better, could you please provide more details about the chat history idea you're referring to? If you could share some context or keywords related to your idea, I'd be happy to discuss it with you.\", name='General'), Message(role='assistant', content=\"I don't have access to any previous messages from other assistants or any prior conversation history with you in this chat. There's no content in our current conversation that references a specific chat history idea you mentioned earlier.\\n\\nIf you'd like to discuss a particular idea about chat histories, I'd be happy to help if you could share what you're referring to.\", name=None)], finish_reason=None)]\n",
      "\n",
      "=== Test with required user_name but default k ===\n",
      "[ChatResponse(messages=[Message(role='assistant', content=\"I apologize, but I'm encountering a technical issue when trying to search your chat history. The database connection that would allow me to retrieve your previous conversations isn't working properly at the moment.\\n\\nWithout access to your chat history, I don't have context about any specific chat history idea you mentioned before. Could you please provide more details about the idea you're referring to? This would help me better assist you with your question.\", name='General'), Message(role='assistant', content='I don\\'t have access to any previous messages from other assistants or any chat history beyond our current conversation. There\\'s nothing in our current exchange that references a specific \"chat history idea\" you mentioned earlier.\\n\\nIf you\\'d like to discuss a particular idea about chat histories, I\\'d be happy to help if you could share those details with me now.', name=None)], finish_reason=None)]\n"
     ]
    },
    {
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-7b9132b397c72415bc7cb1bae1e7f37a\", \"tr-649d2c30cbfa6b7590602d8c8b43d0a9\", \"tr-00572b1cc07581698680e4f2a4063d42\"]",
      "text/plain": [
       "[Trace(trace_id=tr-7b9132b397c72415bc7cb1bae1e7f37a), Trace(trace_id=tr-649d2c30cbfa6b7590602d8c8b43d0a9), Trace(trace_id=tr-00572b1cc07581698680e4f2a4063d42)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test with custom k parameter using pydantic structure\n",
    "# Note: Wrap in list because MLflow pyfunc expects List[ChatRequest]\n",
    "test_input_custom_k = [{\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What was my chat history idea?\"}],\n",
    "    \"custom_inputs\": {\n",
    "        \"filters\": {\"user_name\": \"tanner.wendland@databricks.com\"},\n",
    "        \"k\": 10  # Request 10 records instead of default 3\n",
    "    }\n",
    "}]\n",
    "\n",
    "answer = AGENT.predict(test_input_custom_k)\n",
    "print(\"=== Test with custom k=10 ===\")\n",
    "print(answer)\n",
    "\n",
    "# Test with default k (no custom_inputs provided)\n",
    "test_input_default = [{\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What was my chat history idea?\"}]\n",
    "    # No custom_inputs - should use defaults\n",
    "}]\n",
    "\n",
    "answer_default = AGENT.predict(test_input_default)\n",
    "print(\"\\n=== Test with no custom_inputs (should use defaults) ===\")\n",
    "print(answer_default)\n",
    "\n",
    "# Test with required user_name but no k (should use default k)\n",
    "test_input_required_user = [{\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What was my chat history idea?\"}],\n",
    "    \"custom_inputs\": {\n",
    "        \"filters\": {\"user_name\": \"tanner.wendland@databricks.com\"}\n",
    "        # No k specified - should use default from model_config\n",
    "    }\n",
    "}]\n",
    "\n",
    "answer_required = AGENT.predict(test_input_required_user)\n",
    "print(\"\\n=== Test with required user_name but default k ===\")\n",
    "print(answer_required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0141fcd2-95ff-4d57-bfa4-3c55a38f6946",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c9639d4-1d86-40b3-87b4-b46c8b7be046",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"secert_scope\", \"field-eng\", \"Secret Scope\")\n",
    "dbutils.widgets.text(\"secret_key\", \"app-secret\", \"Secret Key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93d99ca7-c565-4092-9f28-aff21fcebfa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REDACTED]\n"
     ]
    }
   ],
   "source": [
    "secret_scope = dbutils.widgets.get(\"secert_scope\")\n",
    "secret_key = dbutils.widgets.get(\"secret_key\")\n",
    "\n",
    "secret_value = dbutils.secrets.get(scope=secret_scope, key=secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbed8a02-2931-4a9f-aa13-e3f2766bf1c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating endpoint tanner_wendland-default-chat_history_agent_postgres_genie...\n"
     ]
    }
   ],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import EndpointCoreConfigInput, ServedEntityInput, AiGatewayConfig\n",
    "\n",
    "workspace_client = WorkspaceClient()\n",
    "\n",
    "version = uc_registered_model_info.version\n",
    "serving_endpoint_name = model_name.replace(\".\", \"-\")\n",
    "\n",
    "workspace_url = spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
    "\n",
    "config = {\n",
    "        \"served_entities\": [\n",
    "            {\n",
    "                \"name\": serving_endpoint_name,\n",
    "                \"entity_name\": MODEL_NAME_FQN,\n",
    "                \"entity_version\": version,\n",
    "                \"workload_size\": \"Small\",\n",
    "                \"scale_to_zero_enabled\": True,\n",
    "                \"environment_vars\": {\n",
    "                    'DATABRICKS_HOST': workspace_url,\n",
    "                    'DATABRICKS_TOKEN': secret_value\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "ai_gateway_config = {\n",
    "        'inference_table_config': {\n",
    "            'enabled': True,\n",
    "            'catalog_name': target_catalog,\n",
    "            'schema_name': target_schema,\n",
    "            'table_name': \"chat_history_agent_postgres_genie_inference\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "def does_endpoint_exists(endpoint_name):\n",
    "    try:\n",
    "        workspace_client.serving_endpoints.get(endpoint_name)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "if not does_endpoint_exists(serving_endpoint_name):\n",
    "    print(f\"Creating endpoint {serving_endpoint_name}...\")\n",
    "    workspace_client.serving_endpoints.create_and_wait(\n",
    "        serving_endpoint_name,\n",
    "        config=EndpointCoreConfigInput.from_dict(config),\n",
    "        ai_gateway=AiGatewayConfig.from_dict(ai_gateway_config)\n",
    "    )\n",
    "else:\n",
    "    print(f\"Updating endpoint {serving_endpoint_name}...\")\n",
    "    workspace_client.serving_endpoints.update_config_and_wait(\n",
    "        serving_endpoint_name,\n",
    "        served_entities=[ServedEntityInput.from_dict(entity) for entity in config['served_entities']]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02.2-chat-history-agent-pg-genie",
   "widgets": {
    "database_instance_name": {
     "currentValue": "tannerw-adtech-db",
     "nuid": "5935864b-337f-4cea-978f-00fcf2a24646",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "tannerw-adtech-db",
      "label": null,
      "name": "database_instance_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "tannerw-adtech-db",
      "label": null,
      "name": "database_instance_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "embedding_model": {
     "currentValue": "databricks-gte-large-en",
     "nuid": "96111585-d614-405c-960e-ae589ccc89fc",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "databricks-gte-large-en",
      "label": null,
      "name": "embedding_model",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "databricks-gte-large-en",
      "label": null,
      "name": "embedding_model",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "genie_space_id": {
     "currentValue": "01efcca6fdc712d7be87a40ad4a2e33e",
     "nuid": "ac774ec2-f551-4a54-94f9-5c547df32515",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "01efcca6fdc712d7be87a40ad4a2e33e",
      "label": null,
      "name": "genie_space_id",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "01efcca6fdc712d7be87a40ad4a2e33e",
      "label": null,
      "name": "genie_space_id",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "llm_model_serving_endpoint_name": {
     "currentValue": "databricks-claude-3-7-sonnet",
     "nuid": "4e5299b7-86bb-4511-bd44-8d76be56893e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "databricks-claude-3-7-sonnet",
      "label": null,
      "name": "llm_model_serving_endpoint_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "databricks-claude-3-7-sonnet",
      "label": null,
      "name": "llm_model_serving_endpoint_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "postgres_database_name": {
     "currentValue": "databricks_postgres",
     "nuid": "e75a0daa-dd0b-412d-b393-29edb1e3b1f1",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "databricks_postgres",
      "label": null,
      "name": "postgres_database_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "databricks_postgres",
      "label": null,
      "name": "postgres_database_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "secert_scope": {
     "currentValue": "field-eng",
     "nuid": "e227bce8-9119-4ce0-9bd1-7bb37e315a10",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "field-eng",
      "label": "Secret Scope",
      "name": "secert_scope",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "field-eng",
      "label": "Secret Scope",
      "name": "secert_scope",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "secret_key": {
     "currentValue": "app-secret",
     "nuid": "90c15fd3-85b5-4532-9fb1-cd73d8f32360",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "app-secret",
      "label": "Secret Key",
      "name": "secret_key",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "app-secret",
      "label": "Secret Key",
      "name": "secret_key",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "target_catalog": {
     "currentValue": "tanner_wendland",
     "nuid": "9ce71cf8-98af-4e13-8cc0-71dc8c6cf387",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "tanner_wendland",
      "label": null,
      "name": "target_catalog",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "tanner_wendland",
      "label": null,
      "name": "target_catalog",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "target_schema": {
     "currentValue": "default",
     "nuid": "eb61b685-72df-4bd5-bf4e-80e589c9adb5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "default",
      "label": null,
      "name": "target_schema",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "default",
      "label": null,
      "name": "target_schema",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
