{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'databricks-sdk==0.61.0' 'databricks-sdk[notebook]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"source_table_catalog\", \"tanner_wendland_postgres_adtech\")\n",
    "dbutils.widgets.text(\"source_table_database\", \"public\")\n",
    "dbutils.widgets.text(\"sink_catalog\", \"tanner_wendland\")\n",
    "dbutils.widgets.text(\"sink_schema\", \"default\")\n",
    "dbutils.widgets.text(\"vector_search_endpoint\", \"tanner_vs_endpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_table_catalog = dbutils.widgets.get(\"source_table_catalog\")\n",
    "source_table_database = dbutils.widgets.get(\"source_table_database\")\n",
    "sink_catalog = dbutils.widgets.get(\"sink_catalog\")\n",
    "sink_schema = dbutils.widgets.get(\"sink_schema\")\n",
    "vector_search_endpoint = dbutils.widgets.get(\"vector_search_endpoint\")\n",
    "print(source_table_catalog)\n",
    "print(source_table_database)\n",
    "print(sink_catalog)\n",
    "print(sink_schema)\n",
    "print(vector_search_endpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source table: tanner_wendland_postgres_adtech.public.chat_history\n",
      "Destination table: tanner_wendland.default.chat_history\n",
      "Reading source data...\n",
      "Destination table tanner_wendland.default.chat_history exists. Performing incremental load...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17d53c2342b4ec3a1d7cf9abe205193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last processed timestamp: 2025-07-30 17:13:00.622155\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2f06c88a8f4b758ba1601dd5835352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 new records to process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6b4cd892ad4cca80736f2acd87205c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb7737d3bcb4ed6954ce5424fb80e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c7acdd8c5845978587afff92e27f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully appended 2 records to tanner_wendland.default.chat_history\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, TimestampType\n",
    "\n",
    "# Construct full table names using widget values\n",
    "source_table_name = f\"{source_table_catalog}.{source_table_database}.chat_history\"\n",
    "sink_table_name = f\"{sink_catalog}.{sink_schema}.chat_history\"\n",
    "\n",
    "print(f\"Source table: {source_table_name}\")\n",
    "print(f\"Destination table: {sink_table_name}\")\n",
    "\n",
    "# Read source data\n",
    "print(\"Reading source data...\")\n",
    "source_df = spark.table(source_table_name)\n",
    "\n",
    "# Check if destination table exists\n",
    "if spark.catalog.tableExists(sink_table_name):\n",
    "    print(f\"Destination table {sink_table_name} exists. Performing incremental load...\")\n",
    "    \n",
    "    # Read existing destination table\n",
    "    existing_df = spark.table(sink_table_name)\n",
    "    \n",
    "    # Get the maximum timestamp/id from existing data for incremental load\n",
    "    # Assuming there's a created_at or updated_at timestamp column\n",
    "    # If not, we can use id or another sequential column\n",
    "    max_timestamp = existing_df.agg({\"created_at\": \"max\"}).collect()[0][0]\n",
    "    \n",
    "    if max_timestamp:\n",
    "        print(f\"Last processed timestamp: {max_timestamp}\")\n",
    "        # Filter source data for incremental load\n",
    "        incremental_df = source_df.filter(source_df.created_at > max_timestamp)\n",
    "    else:\n",
    "        # If max_timestamp is None, load all data\n",
    "        incremental_df = source_df\n",
    "        \n",
    "    print(f\"Found {incremental_df.count()} new records to process\")\n",
    "    \n",
    "    if incremental_df.count() > 0:\n",
    "        # Append new data to existing table\n",
    "        incremental_df.write.mode(\"append\").saveAsTable(sink_table_name)\n",
    "        print(f\"Successfully appended {incremental_df.count()} records to {sink_table_name}\")\n",
    "    else:\n",
    "        print(\"No new records to process\")\n",
    "        \n",
    "else:\n",
    "    # Destination table doesn't exist, create it with all source data\n",
    "    print(f\"Destination table {sink_table_name} doesn't exist. Creating with full load...\")\n",
    "\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE {sink_table_name} (\n",
    "            id INTEGER NOT NULL,\n",
    "            chat_id STRING NOT NULL,\n",
    "            user_name STRING NOT NULL,\n",
    "            message_type STRING NOT NULL,\n",
    "            message_content STRING NOT NULL,\n",
    "            created_at TIMESTAMP NOT NULL,\n",
    "            message_order INTEGER NOT NULL,\n",
    "            PRIMARY KEY (id)\n",
    "        )\n",
    "        USING DELTA \n",
    "        TBLPROPERTIES (delta.enableChangeDataFeed = true)\n",
    "    \"\"\")\n",
    "\n",
    "    record_count = source_df.count()\n",
    "    source_df.write.mode(\"overwrite\").saveAsTable(sink_table_name)\n",
    "    \n",
    "    print(f\"Successfully created {sink_table_name} with {record_count} records and primary key constraint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb7b38c49614f349f2545ad33b58a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final table tanner_wendland.default.chat_history contains 4 total records\n",
      "\n",
      "Sample of latest records:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ae1d8636cd4a178c71fec70d281bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>chat_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>message_type</th>\n",
       "      <th>message_content</th>\n",
       "      <th>created_at</th>\n",
       "      <th>message_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>c7cd4361-5145-4ddf-92f3-4704931a1864</td>\n",
       "      <td>tanner.wendland@databricks.com</td>\n",
       "      <td>ASSISTANT</td>\n",
       "      <td>Yes, I'm working now! How can I help you today?</td>\n",
       "      <td>2025-07-30 22:13:00.622155</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>c7cd4361-5145-4ddf-92f3-4704931a1864</td>\n",
       "      <td>tanner.wendland@databricks.com</td>\n",
       "      <td>USER</td>\n",
       "      <td>Are you working now?</td>\n",
       "      <td>2025-07-30 22:12:58.658630</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>c7cd4361-5145-4ddf-92f3-4704931a1864</td>\n",
       "      <td>tanner.wendland@databricks.com</td>\n",
       "      <td>ASSISTANT</td>\n",
       "      <td>Error calling model serving endpoint: INVALID_PARAMETER_VALUE: Missing required Chat parameter: 'messages'</td>\n",
       "      <td>2025-07-30 22:06:36.518033</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>c7cd4361-5145-4ddf-92f3-4704931a1864</td>\n",
       "      <td>tanner.wendland@databricks.com</td>\n",
       "      <td>USER</td>\n",
       "      <td>test chat</td>\n",
       "      <td>2025-07-30 22:06:36.082661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[id: int, chat_id: string, user_name: string, message_type: string, message_content: string, created_at: timestamp, message_order: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display final table info\n",
    "final_df = spark.table(sink_table_name)\n",
    "print(f\"\\nFinal table {sink_table_name} contains {final_df.count()} total records\")\n",
    "print(\"\\nSample of latest records:\")\n",
    "display(final_df.orderBy(\"created_at\", ascending=False).limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector search endpoint one-env-shared-endpoint-7 already exists\n",
      "Vector search index tanner_wendland.default.chat_history_index already exists\n"
     ]
    }
   ],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.vectorsearch import VectorIndexType, DeltaSyncVectorIndexSpecRequest, PipelineType, EmbeddingSourceColumn, EndpointType\n",
    "\n",
    "# Initialize the Workspace client\n",
    "w = WorkspaceClient()\n",
    "index_name = f\"{sink_table_name}_index\"\n",
    "\n",
    "vs_exists = any(vs.name == vector_search_endpoint for vs in w.vector_search_endpoints.list_endpoints())\n",
    "\n",
    "if not vs_exists:\n",
    "    w.vector_search_endpoints.create_endpoint(\n",
    "        name=vector_search_endpoint,\n",
    "        endpoint_type=EndpointType.STANDARD,\n",
    "    )\n",
    "else:\n",
    "    print(f\"Vector search endpoint {vector_search_endpoint} already exists\")\n",
    "\n",
    "index_exists = any(index.name == index_name for index in w.vector_search_indexes.list_indexes(vector_search_endpoint))\n",
    "\n",
    "if not index_exists:\n",
    "    index_spec = DeltaSyncVectorIndexSpecRequest(\n",
    "        source_table=sink_table_name,\n",
    "        pipeline_type=PipelineType.CONTINUOUS,\n",
    "        embedding_source_columns=[EmbeddingSourceColumn(name=\"message_content\", embedding_model_endpoint_name=\"databricks-gte-large-en\")]\n",
    "    )\n",
    "\n",
    "    index = w.vector_search_indexes.create_index(\n",
    "        endpoint_name=vector_search_endpoint,\n",
    "        name=index_name,\n",
    "        index_type=VectorIndexType.DELTA_SYNC,\n",
    "        delta_sync_index_spec=index_spec,\n",
    "        primary_key=\"id\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"Vector search index {index_name} already exists\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
